"""
Simple ChatGPT-style Streamlit web application for building damage analysis
"""

import streamlit as st
import os
import asyncio
from concurrent.futures import ThreadPoolExecutor
import time

# Suppress HuggingFace warnings
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["TRANSFORMERS_VERBOSITY"] = "error"

from datetime import datetime
from pathlib import Path
import logging
from typing import Dict, Any, List, Optional

# Import the new simple UI
from ui.ui_components import render_simple_chatgpt_ui

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Reduce verbosity of external libraries
logging.getLogger("faiss").setLevel(logging.WARNING)
logging.getLogger("transformers").setLevel(logging.WARNING)
logging.getLogger("sentence_transformers").setLevel(logging.WARNING)

# Import our analysis modules
try:
    from langchain_integration import analyze_building_damage, DamageAnalysisOutput
    from config import DAMAGE_CATEGORIES, CACHE_DIR, LOGS_DIR
    from models import BuildingDamageAnalysisModel

    # FAISS Vector store ì§ì ‘ ì‚¬ìš©
    try:
        from vector_store_faiss import create_faiss_vector_store

        VECTOR_STORE_AVAILABLE = True
        logger.info("FAISS vector store available")
    except Exception as ve:
        logger.warning(f"FAISS vector store not available: {ve}")
        VECTOR_STORE_AVAILABLE = False

        @st.cache_resource
        def create_faiss_vector_store():
            """Fallback vector store function"""
            logger.warning("Using fallback vector store")
            return None

    MODULES_LOADED = True
except ImportError as e:
    st.error(f"ëª¨ë“ˆ ë¡œë”© ì˜¤ë¥˜: {e}")
    st.error("í•„ìš”í•œ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°œë°œìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
    MODULES_LOADED = False
    VECTOR_STORE_AVAILABLE = False
    # Fallback values
    DAMAGE_CATEGORIES = {}
    CACHE_DIR = Path("./cache")
    LOGS_DIR = Path("./logs")

    @st.cache_resource
    def create_faiss_vector_store():
        return None

    def analyze_building_damage(*args, **kwargs):
        return {"error": "ë¶„ì„ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}


# Create directories
UPLOAD_DIR = CACHE_DIR / "uploads"
RESULTS_DIR = CACHE_DIR / "results"

for directory in [UPLOAD_DIR, RESULTS_DIR]:
    directory.mkdir(parents=True, exist_ok=True)


# Performance optimization: Thread pool for async operations
@st.cache_resource
def get_thread_pool():
    """Get cached thread pool for async operations"""
    return ThreadPoolExecutor(max_workers=2)


@st.cache_data(ttl=300)  # Cache for 5 minutes
def get_standard_repair_data(damage_type: str, area: float) -> Dict[str, Any]:
    """Get cached standard repair data"""
    # This would normally query the vector store
    # For now, return mock data based on damage type and area

    base_materials = {
        "ê· ì—´": ["ì‹œë©˜íŠ¸ ëª¨ë¥´íƒ€ë¥´", "ì—í­ì‹œ ìˆ˜ì§€", "ë°©ìˆ˜ì¬"],
        "ëˆ„ìˆ˜": ["ë°©ìˆ˜ ì‹œíŠ¸", "ì‹¤ë¦¬ì½˜ ì‹¤ë€íŠ¸", "ìš°ë ˆíƒ„ ë°©ìˆ˜ì¬"],
        "í™”ì¬": ["ë‚´í™”ì¬", "ë‹¨ì—´ì¬", "ì„ê³ ë³´ë“œ"],
        "ë¶€ì‹": ["ë°©ì²­ì œ", "ì•„ì—°ë„ê¸ˆê°•íŒ", "ë¶€ì‹ë°©ì§€ì œ"],
    }

    base_equipment = {
        "ê· ì—´": ["ë¯¹ì„œê¸°", "ì••ì¶•ê¸°", "ì£¼ì…ê¸°"],
        "ëˆ„ìˆ˜": ["í† ì¹˜", "ë¡¤ëŸ¬", "ì••ì°©ê¸°"],
        "í™”ì¬": ["ì ˆë‹¨ê¸°", "ìš©ì ‘ê¸°", "ë¦¬í”„íŠ¸"],
        "ë¶€ì‹": ["ìƒŒë”©ê¸°", "ìŠ¤í”„ë ˆì´ê±´", "ë¸ŒëŸ¬ì‹œ"],
    }

    labor_composition = {
        "ê· ì—´": {"íŠ¹ê¸‰ê¸°ëŠ¥ì‚¬": 1, "ê³ ê¸‰ê¸°ëŠ¥ì‚¬": 1, "ë³´í†µì¸ë¶€": 2},
        "ëˆ„ìˆ˜": {"íŠ¹ê¸‰ê¸°ëŠ¥ì‚¬": 1, "ê³ ê¸‰ê¸°ëŠ¥ì‚¬": 2, "ë³´í†µì¸ë¶€": 1},
        "í™”ì¬": {"íŠ¹ê¸‰ê¸°ëŠ¥ì‚¬": 2, "ê³ ê¸‰ê¸°ëŠ¥ì‚¬": 2, "ë³´í†µì¸ë¶€": 3},
        "ë¶€ì‹": {"íŠ¹ê¸‰ê¸°ëŠ¥ì‚¬": 1, "ê³ ê¸‰ê¸°ëŠ¥ì‚¬": 1, "ë³´í†µì¸ë¶€": 1},
    }

    # Calculate costs based on area
    material_cost_per_sqm = {"ê· ì—´": 25000, "ëˆ„ìˆ˜": 35000, "í™”ì¬": 80000, "ë¶€ì‹": 45000}
    labor_cost_per_sqm = {"ê· ì—´": 15000, "ëˆ„ìˆ˜": 20000, "í™”ì¬": 40000, "ë¶€ì‹": 25000}

    damage_key = next(
        (key for key in base_materials.keys() if key in damage_type), "ê· ì—´"
    )

    return {
        "materials": base_materials.get(damage_key, base_materials["ê· ì—´"]),
        "equipment": base_equipment.get(damage_key, base_equipment["ê· ì—´"]),
        "labor": labor_composition.get(damage_key, labor_composition["ê· ì—´"]),
        "material_cost": material_cost_per_sqm.get(damage_key, 25000) * area,
        "labor_cost": labor_cost_per_sqm.get(damage_key, 15000) * area,
        "duration_days": max(1, int(area / 10)),  # Rough estimate
    }


@st.cache_data(ttl=600)  # Cache for 10 minutes
def save_uploaded_file(uploaded_file_bytes: bytes, filename: str) -> Path:
    """Save uploaded file and return path with caching"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    file_extension = Path(filename).suffix
    cached_filename = f"upload_{timestamp}{file_extension}"
    file_path = UPLOAD_DIR / cached_filename

    with open(file_path, "wb") as f:
        f.write(uploaded_file_bytes)

    return file_path


def analyze_damage_with_ai_async(
    image_path: str, area: float, user_message: str
) -> str:
    """Async wrapper for damage analysis"""
    return analyze_damage_with_ai(image_path, area, user_message)


def analyze_damage_with_ai(image_path: str, area: float, user_message: str) -> str:
    """Analyze building damage using AI with performance optimization"""
    if not MODULES_LOADED:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ë¶„ì„ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°œë°œìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."

    start_time = time.time()

    try:
        # Initialize vector store if not exists and available
        if "vector_store" not in st.session_state:
            if VECTOR_STORE_AVAILABLE:
                with st.spinner("í‘œì¤€ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œë”©í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    try:
                        st.session_state.vector_store = create_faiss_vector_store()
                        logger.info("Vector store initialized successfully")
                    except Exception as e:
                        logger.error(f"Failed to initialize vector store: {e}")
                        st.session_state.vector_store = None
            else:
                logger.warning("Vector store not available, using fallback mode")
                st.session_state.vector_store = None

        # Perform damage analysis with progress tracking
        progress_bar = st.progress(0)
        status_text = st.empty()

        status_text.text("ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
        progress_bar.progress(25)

        with st.spinner("AIê°€ ê±´ë¬¼ í”¼í•´ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            damage_result = analyze_building_damage(
                image_path=image_path,
                query=f"{user_message} (í”¼í•´ ë©´ì : {area} mÂ²)",
                device="cpu",
                generate_report=True,
            )

        progress_bar.progress(50)
        status_text.text("ğŸ“Š í‘œì¤€ ë°ì´í„° ê²€ìƒ‰ ì¤‘...")

        # Extract analysis result
        if isinstance(damage_result, dict) and "analysis_result" in damage_result:
            analysis_result = damage_result["analysis_result"]

            # Handle both DamageAnalysisOutput object and dictionary
            if hasattr(analysis_result, "damage_analysis"):
                damage_analysis = analysis_result.damage_analysis
            elif isinstance(analysis_result, dict):
                damage_analysis = analysis_result.get("damage_analysis", {})
            else:
                damage_analysis = {}

            progress_bar.progress(75)
            status_text.text("ğŸ’° ë¹„ìš© ì‚°ì • ì¤‘...")

            # Format the response with enhanced details
            response = format_comprehensive_analysis_response(damage_analysis, area)

            progress_bar.progress(100)
            status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")

            # Clear progress indicators after a short delay
            time.sleep(1)
            progress_bar.empty()
            status_text.empty()

            analysis_time = time.time() - start_time
            logger.info(f"Analysis completed in {analysis_time:.2f} seconds")

            return response
        else:
            return "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

    except Exception as e:
        logger.error(f"Analysis error: {e}")
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


def format_comprehensive_analysis_response(
    damage_analysis: Dict[str, Any], area: float
) -> str:
    """Format comprehensive analysis response with all required fields from the image"""

    # Extract key information
    damage_types = damage_analysis.get("damage_types", ["ì¼ë°˜ í”¼í•´"])
    primary_damage = damage_types[0] if damage_types else "ì¼ë°˜ í”¼í•´"
    severity_score = damage_analysis.get("severity_score", 3)
    affected_areas = damage_analysis.get("affected_areas", ["ì „ì²´ ì˜ì—­"])
    confidence_level = damage_analysis.get("confidence_level", 0.8)

    # Get standard repair data
    repair_data = get_standard_repair_data(primary_damage, area)

    # Create severity description
    severity_descriptions = {
        1: "ê²½ë¯¸í•œ í”¼í•´",
        2: "ê°€ë²¼ìš´ í”¼í•´",
        3: "ë³´í†µ í”¼í•´",
        4: "ì‹¬ê°í•œ í”¼í•´",
        5: "ë§¤ìš° ì‹¬ê°í•œ í”¼í•´",
    }
    severity_desc = severity_descriptions.get(severity_score, "ë³´í†µ í”¼í•´")

    # Calculate total costs
    total_material_cost = repair_data["material_cost"]
    total_labor_cost = repair_data["labor_cost"]
    total_cost = total_material_cost + total_labor_cost

    # Format response with all required fields
    response = f"""
# ğŸ—ï¸ ê±´ë¬¼ í”¼í•´ ë¶„ì„ ì¢…í•© ë³´ê³ ì„œ

## ğŸ“‹ ê¸°ë³¸ ì •ë³´
| í•­ëª© | ë‚´ìš© |
|------|------|
| **ë¶„ì„ ì¼ì‹œ** | {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')} |
| **ë¶„ì„ ë©´ì ** | {area:,.1f} mÂ² |
| **ë¶„ì„ ì‹ ë¢°ë„** | {confidence_level:.1%} |
| **ë³´ê³ ì„œ ID** | RPT-{datetime.now().strftime('%Y%m%d%H%M%S')} |

---

## ğŸ” í”¼í•´ í˜„í™© ë¶„ì„

### ğŸ“ í”¼í•´ ë¶€ìœ„
- **ì£¼ìš” í”¼í•´ ì˜ì—­**: {', '.join(affected_areas)}
- **í”¼í•´ ë²”ìœ„**: {area:,.1f} mÂ²

### ğŸš¨ í”¼í•´ ìœ í˜•  
- **ì£¼ìš” í”¼í•´**: {primary_damage}
- **ì„¸ë¶€ í”¼í•´ ìœ í˜•**: {', '.join(damage_types)}
- **í”¼í•´ ì‹¬ê°ë„**: {severity_score}/5 ({severity_desc})

---

## ğŸ”§ ë³µêµ¬ ë°©ë²• ë° ê³µì¢…

### ğŸ“‹ ë³µêµ¬ ë°©ë²•
"""

    # Add repair methods based on damage type
    repair_methods = {
        "ê· ì—´": [
            "ê· ì—´ ë¶€ìœ„ ì²­ì†Œ ë° ì´ë¬¼ì§ˆ ì œê±°",
            "ì—í­ì‹œ ìˆ˜ì§€ ì£¼ì…ì„ í†µí•œ ê· ì—´ ë³´ìˆ˜",
            "í‘œë©´ ë§ˆê° ë° ë°©ìˆ˜ ì²˜ë¦¬",
        ],
        "ëˆ„ìˆ˜": [
            "ëˆ„ìˆ˜ ì›ì¸ íŒŒì•… ë° ì°¨ë‹¨",
            "ê¸°ì¡´ ë°©ìˆ˜ì¸µ ì œê±°",
            "ì‹ ê·œ ë°©ìˆ˜ì¸µ ì‹œê³µ",
            "ë§ˆê°ì¬ ë³µêµ¬",
        ],
        "í™”ì¬": ["ì†ìƒ ë¶€ì¬ ì² ê±°", "êµ¬ì¡° ë³´ê°•", "ë‚´í™”ì¬ ì‹œê³µ", "ë§ˆê°ì¬ ë³µêµ¬"],
        "ë¶€ì‹": ["ë¶€ì‹ ë¶€ìœ„ ì œê±°", "ë°©ì²­ ì²˜ë¦¬", "ë³´ê°•ì¬ ì„¤ì¹˜", "ë³´í˜¸ ë„ì¥"],
    }

    damage_key = next(
        (key for key in repair_methods.keys() if key in primary_damage), "ê· ì—´"
    )
    methods = repair_methods.get(damage_key, repair_methods["ê· ì—´"])

    for i, method in enumerate(methods, 1):
        response += f"\n{i}. {method}"

    response += f"""

### ğŸ—ï¸ ë³µêµ¬ ê³µì¢…
- **ì£¼ìš” ê³µì¢…**: {primary_damage} ë³´ìˆ˜ê³µì‚¬
- **ì„¸ë¶€ ê³µì¢…**: 
  - ì² ê±°ê³µì‚¬
  - ë³´ìˆ˜ê³µì‚¬  
  - ë°©ìˆ˜ê³µì‚¬
  - ë§ˆê°ê³µì‚¬

### ğŸ“ ê³µì¢…ëª… (ê±´ì„¤ê³µì‚¬ í‘œì¤€í’ˆì…ˆ ê¸°ì¤€)
- **{primary_damage} ë³´ìˆ˜**: í‘œì¤€í’ˆì…ˆ ê¸°ì¤€ ì ìš©
- **ì ìš© ê¸°ì¤€**: êµ­í† êµí†µë¶€ ê±´ì„¤ê³µì‚¬ í‘œì¤€í’ˆì…ˆ 2024ë…„ ê¸°ì¤€

---

## ğŸ› ï¸ ë³µêµ¬ ì¬ë£Œ ë° ì¥ë¹„

### ğŸ“¦ ì£¼ìš” ìì¬
"""

    for i, material in enumerate(repair_data["materials"], 1):
        response += f"\n{i}. {material}"

    response += f"""

### âš™ï¸ í•„ìš” ì¥ë¹„
"""

    for i, equipment in enumerate(repair_data["equipment"], 1):
        response += f"\n{i}. {equipment}"

    response += f"""

---

## ğŸ‘· ì¸ë ¥ êµ¬ì„±

### ğŸ‘¥ ì†Œìš” ì¸ë ¥
| ì§ì¢… | ì¸ì› | ì—­í•  |
|------|------|------|
"""

    for job_type, count in repair_data["labor"].items():
        roles = {
            "íŠ¹ê¸‰ê¸°ëŠ¥ì‚¬": "í˜„ì¥ ì´ê´„, ê¸°ìˆ  ì§€ë„",
            "ê³ ê¸‰ê¸°ëŠ¥ì‚¬": "ì „ë¬¸ ì‘ì—… ìˆ˜í–‰",
            "ë³´í†µì¸ë¶€": "ë³´ì¡° ì‘ì—…, ìì¬ ìš´ë°˜",
        }
        response += f"| {job_type} | {count}ëª… | {roles.get(job_type, 'ì‘ì—… ìˆ˜í–‰')} |\n"

    response += f"""

---

## â° ë³µêµ¬ ê¸°ê°„

### ğŸ“… ì˜ˆìƒ ê³µì‚¬ ê¸°ê°„
- **ì´ ê³µì‚¬ ê¸°ê°„**: {repair_data['duration_days']}ì¼
- **ì‘ì—… ë‹¨ê³„ë³„ ê¸°ê°„**:
  - ì¤€ë¹„ ë° ì² ê±°: 1ì¼
  - ì£¼ìš” ë³´ìˆ˜ ì‘ì—…: {max(1, repair_data['duration_days']-2)}ì¼  
  - ë§ˆê° ë° ì •ë¦¬: 1ì¼

---

## ğŸ’° ë¹„ìš© ì‚°ì •

### ğŸ’µ ìì¬ë¹„ ë‹¨ê°€
| êµ¬ë¶„ | ë‹¨ê°€ | ìˆ˜ëŸ‰ | ê¸ˆì•¡ |
|------|------|------|------|
| ìì¬ë¹„ | {total_material_cost/area:,.0f}ì›/mÂ² | {area:,.1f}mÂ² | {total_material_cost:,.0f}ì› |

### ğŸ‘· ë…¸ë¬´ë¹„  
| êµ¬ë¶„ | ë‹¨ê°€ | ìˆ˜ëŸ‰ | ê¸ˆì•¡ |
|------|------|------|------|
| ë…¸ë¬´ë¹„ | {total_labor_cost/area:,.0f}ì›/mÂ² | {area:,.1f}mÂ² | {total_labor_cost:,.0f}ì› |

### ğŸ“Š ì´ ë¹„ìš© ìš”ì•½
| í•­ëª© | ê¸ˆì•¡ | ë¹„ìœ¨ |
|------|------|------|
| **ìì¬ë¹„** | {total_material_cost:,.0f}ì› | {(total_material_cost/total_cost)*100:.1f}% |
| **ë…¸ë¬´ë¹„** | {total_labor_cost:,.0f}ì› | {(total_labor_cost/total_cost)*100:.1f}% |
| **ì´ ê³µì‚¬ë¹„** | **{total_cost:,.0f}ì›** | **100%** |
| **mÂ²ë‹¹ ë‹¨ê°€** | {total_cost/area:,.0f}ì›/mÂ² | - |

---

## ğŸ”§ ìˆ˜ë¦¬ ìš°ì„ ìˆœìœ„ ë° ê¶Œì¥ì‚¬í•­

### ğŸš¨ ìš°ì„ ìˆœìœ„
"""

    if severity_score >= 4:
        response += """
- **ë“±ê¸‰**: ğŸ”´ **ê¸´ê¸‰ (1ìˆœìœ„)**
- **ì¡°ì¹˜ ê¸°í•œ**: ì¦‰ì‹œ (24ì‹œê°„ ì´ë‚´)
- **ê¶Œì¥ ì¡°ì¹˜**: ì•ˆì „ìƒì˜ ì´ìœ ë¡œ ì¦‰ì‹œ ì „ë¬¸ê°€ ìƒë‹´ ë° ì‘ê¸‰ ì¡°ì¹˜ í•„ìš”
"""
    elif severity_score == 3:
        response += """
- **ë“±ê¸‰**: ğŸŸ¡ **ë†’ìŒ (2ìˆœìœ„)**  
- **ì¡°ì¹˜ ê¸°í•œ**: 2ì£¼ ì´ë‚´
- **ê¶Œì¥ ì¡°ì¹˜**: ë¹ ë¥¸ ì‹œì¼ ë‚´ì— ìˆ˜ë¦¬ë¥¼ ì§„í–‰í•˜ì—¬ í”¼í•´ í™•ì‚° ë°©ì§€
"""
    else:
        response += """
- **ë“±ê¸‰**: ğŸŸ¢ **ë³´í†µ (3ìˆœìœ„)**
- **ì¡°ì¹˜ ê¸°í•œ**: 1ê°œì›” ì´ë‚´  
- **ê¶Œì¥ ì¡°ì¹˜**: ê³„íšì ìœ¼ë¡œ ìˆ˜ë¦¬ë¥¼ ì§„í–‰í•˜ë˜ ì •ê¸°ì  ì ê²€ ì‹¤ì‹œ
"""

    response += f"""

### âš ï¸ ì•ˆì „ ì£¼ì˜ì‚¬í•­
"""

    if severity_score >= 4:
        response += """
- âš ï¸ **ì¦‰ì‹œ ëŒ€í”¼ ê³ ë ¤**: êµ¬ì¡°ì  ì•ˆì „ì„± ë¬¸ì œ ê°€ëŠ¥ì„±
- âš ï¸ **ì¶œì… ì œí•œ**: í•´ë‹¹ ì˜ì—­ ì‚¬ìš© ê¸ˆì§€
- âš ï¸ **ì „ë¬¸ê°€ ì§„ë‹¨**: êµ¬ì¡° ì—”ì§€ë‹ˆì–´ ì •ë°€ ì§„ë‹¨ í•„ìˆ˜
- âš ï¸ **ì‘ê¸‰ ì¡°ì¹˜**: ì„ì‹œ ë³´ê°• ë˜ëŠ” ì°¨ë‹¨ ì¡°ì¹˜ í•„ìš”
"""
    elif severity_score >= 3:
        response += """
- âš ï¸ **ì£¼ì˜ ê¹Šì€ ì‚¬ìš©**: í•˜ì¤‘ ì œí•œ ë° ì§„ë™ ë°©ì§€
- âš ï¸ **ì •ê¸° ì ê²€**: ì£¼ 1íšŒ ì´ìƒ ìƒíƒœ í™•ì¸
- âš ï¸ **í™•ì‚° ë°©ì§€**: ë°©ìˆ˜ ì²˜ë¦¬ ë“± ì¶”ê°€ í”¼í•´ ë°©ì§€ ì¡°ì¹˜
- âš ï¸ **ëª¨ë‹ˆí„°ë§**: ê· ì—´ ì§„í–‰ ìƒí™© ì§€ì† ê´€ì°°
"""
    else:
        response += """
- âœ… **ì¼ë°˜ ì•ˆì „ìˆ˜ì¹™ ì¤€ìˆ˜**: ê¸°ë³¸ì ì¸ ê±´ë¬¼ ì‚¬ìš© ìˆ˜ì¹™ ì¤€ìˆ˜
- âœ… **ì •ê¸° ìœ ì§€ë³´ìˆ˜**: ì›” 1íšŒ ì´ìƒ ì ê²€ ì‹¤ì‹œ
- âœ… **ì˜ˆë°© ì¡°ì¹˜**: ìŠµë„ ê´€ë¦¬ ë° í™˜ê¸° ë“± ì˜ˆë°© ê´€ë¦¬
"""

    response += f"""

---

## ğŸ“ ì¶”ê°€ ì•ˆë‚´

### ğŸ” ì •ë°€ ì§„ë‹¨ ê¶Œì¥
- ë³¸ ë¶„ì„ì€ AI ê¸°ë°˜ 1ì°¨ ì§„ë‹¨ ê²°ê³¼ì…ë‹ˆë‹¤
- ì •í™•í•œ ì§„ë‹¨ì„ ìœ„í•´ì„œëŠ” ì „ë¬¸ê°€ì˜ í˜„ì¥ ì¡°ì‚¬ê°€ í•„ìš”í•©ë‹ˆë‹¤
- êµ¬ì¡°ì  ì•ˆì „ì„± ê²€í† ê°€ í•„ìš”í•œ ê²½ìš° êµ¬ì¡° ì—”ì§€ë‹ˆì–´ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤

### ğŸ“‹ í‘œì¤€í’ˆì…ˆ ì ìš© ì•ˆë‚´  
- ë³¸ ë¹„ìš© ì‚°ì •ì€ ê±´ì„¤ê³µì‚¬ í‘œì¤€í’ˆì…ˆì„ ê¸°ì¤€ìœ¼ë¡œ í•©ë‹ˆë‹¤
- ì‹¤ì œ ì‹œê³µ ì‹œ í˜„ì¥ ì—¬ê±´ì— ë”°ë¼ ë¹„ìš©ì´ ë³€ë™ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì •í™•í•œ ê²¬ì ì€ ì „ë¬¸ ì‹œê³µì—…ì²´ ìƒë‹´ì„ í†µí•´ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤

### ğŸ’¬ ì¶”ê°€ ë¬¸ì˜
ë” ìì„¸í•œ ë¶„ì„ì´ë‚˜ ì „ë¬¸ê°€ ìƒë‹´ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ì£¼ì„¸ìš”!

---
*ğŸ“… ë³´ê³ ì„œ ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}*  
*ğŸ¤– ë¶„ì„ ì‹œìŠ¤í…œ: Tumblr AI ê±´ë¬¼ í”¼í•´ ë¶„ì„ ì‹œìŠ¤í…œ v2.0*
"""

    return response


def main():
    """Main application function"""

    # Render the simple ChatGPT UI and get user inputs
    user_message, uploaded_file, area_input, send_button = render_simple_chatgpt_ui()

    # Process the message if send button was clicked and there's a message
    if send_button and user_message:
        # If there's an uploaded file, save it and analyze
        if uploaded_file is not None:
            try:
                # Save the uploaded file
                file_path = save_uploaded_file(
                    uploaded_file.getvalue(), uploaded_file.name
                )

                # Analyze the damage
                analysis_result = analyze_damage_with_ai(
                    str(file_path), area_input, user_message
                )

                # The analysis result is already added to session state in render_simple_chatgpt_ui
                # We just need to update the last assistant message with our analysis
                if (
                    st.session_state.messages
                    and st.session_state.messages[-1]["role"] == "assistant"
                ):
                    # Replace the OpenAI response with our detailed analysis
                    st.session_state.messages[-1]["content"] = analysis_result
                    st.rerun()

            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

        # If no image was uploaded, the OpenAI response will be used as-is


if __name__ == "__main__":
    main()
