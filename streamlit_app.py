"""
Simple ChatGPT-style Streamlit web application for building damage analysis
í™˜ê²½ë³„ ì„±ëŠ¥ ìµœì í™” ì ìš©
"""

import streamlit as st
import logging
from datetime import datetime
import gc
import os

# ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ import (ì„ íƒì )
try:
    import psutil

    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

# Import UI components
from ui.ui_components import render_simple_chatgpt_ui

# Import app modules with optimization
from app.config import setup_directories, get_app_config, optimize_for_environment
from app.data_processor import (
    save_uploaded_file,
    validate_uploaded_file,
    validate_area_input,
    validate_image_content,
)
from app.analysis_engine import AnalysisEngine

# í™˜ê²½ë³„ ìµœì í™” ì ìš©
optimize_for_environment()

# ì„¤ì • ì •ë³´ í™•ì¸
app_config = get_app_config()

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í™˜ê²½ ì •ë³´ ë¡œê¹…
logger.info(f"ğŸš€ ì•± ì‹œì‘ - í™˜ê²½: {app_config['environment']}")
logger.info(
    f"ğŸ“Š ì„¤ì •: {app_config['device']}, ì´ë¯¸ì§€ ìµœëŒ€ í¬ê¸°: {app_config['max_image_size']}"
)


# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬ í•¨ìˆ˜
def log_memory_usage(stage: str):
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ë¡œê·¸ì— ê¸°ë¡"""
    if PSUTIL_AVAILABLE:
        try:
            process = psutil.Process()
            memory_info = process.memory_info()
            memory_mb = memory_info.rss / 1024 / 1024
            logger.info(f"{stage} - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_mb:.1f}MB")
            return memory_mb
        except Exception as e:
            logger.debug(f"ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
            return 0
    return 0


def cleanup_memory_if_needed():
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìœ¼ë©´ ì •ë¦¬"""
    if PSUTIL_AVAILABLE:
        try:
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024

            # 800MB ì´ìƒ ì‚¬ìš© ì‹œ ì •ë¦¬ (ì„±ëŠ¥ ìš°ì„ ìœ¼ë¡œ ì„ê³„ê°’ ë†’ì„)
            if memory_mb > 800:
                logger.warning(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ({memory_mb:.1f}MB), ì •ë¦¬ ì‹¤í–‰")

                # ì„¸ì…˜ ë©”ì‹œì§€ ì •ë¦¬ (ì ë‹¹íˆ)
                if (
                    "messages" in st.session_state
                    and len(st.session_state.messages) > 20
                ):
                    st.session_state.messages = st.session_state.messages[
                        -10:
                    ]  # ìµœì‹  10ê°œ ìœ ì§€
                    logger.info("ì„¸ì…˜ ë©”ì‹œì§€ ì •ë¦¬ (ìµœì‹  10ê°œ ìœ ì§€)")

                # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                gc.collect()

                # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬
                try:
                    import torch

                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        torch.cuda.synchronize()
                except ImportError:
                    pass

                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                cleanup_temp_files()

                logger.info("ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")

        except Exception as e:
            logger.debug(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì˜¤ë¥˜: {e}")


def cleanup_temp_files():
    """ì„ì‹œ íŒŒì¼ë“¤ ì •ë¦¬"""
    try:
        import tempfile
        import shutil
        from pathlib import Path

        # ì„ì‹œ ë””ë ‰í† ë¦¬ì—ì„œ ì˜¤ë˜ëœ íŒŒì¼ë“¤ ì‚­ì œ (2ì‹œê°„ ì´ìƒ)
        temp_dir = Path(tempfile.gettempdir())

        current_time = datetime.now().timestamp()
        for file_path in temp_dir.glob("tmp*"):
            try:
                if file_path.is_file():
                    file_age = current_time - file_path.stat().st_mtime
                    if file_age > 7200:  # 2ì‹œê°„
                        file_path.unlink()
            except Exception:
                continue

        # ìºì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ (4ì‹œê°„ ì´ìƒ)
        cache_dir = Path("./cache")
        if cache_dir.exists():
            for file_path in cache_dir.rglob("*"):
                try:
                    if file_path.is_file():
                        file_age = current_time - file_path.stat().st_mtime
                        if file_age > 14400:  # 4ì‹œê°„
                            file_path.unlink()
                except Exception:
                    continue

    except Exception as e:
        logger.debug(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì˜¤ë¥˜: {e}")


# Initialize analysis engine with optimization
@st.cache_resource
def get_analysis_engine():
    """ìºì‹œëœ ë¶„ì„ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤"""
    return AnalysisEngine()


analysis_engine = get_analysis_engine()


def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ í•¨ìˆ˜ (ì„±ëŠ¥ ìš°ì„ )"""

    upload_dir, _ = setup_directories()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì•ˆì „í•˜ê²Œ)
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "analysis_running" not in st.session_state:
        st.session_state.analysis_running = False
    if "last_processed_file" not in st.session_state:
        st.session_state.last_processed_file = None
    if "processing_done" not in st.session_state:
        st.session_state.processing_done = False

    # ìœ„ì ¯ ìƒíƒœ ì´ˆê¸°í™” (UI ìœ„ì ¯ë“¤ì„ ìœ„í•œ ì•ˆì „í•œ ì´ˆê¸°í™”)
    if "area_input" not in st.session_state:
        st.session_state.area_input = 100.0
    if "uploaded_file" not in st.session_state:
        st.session_state.uploaded_file = None

    # ì•± ì‹œì‘ ì‹œ ë©”ëª¨ë¦¬ ì •ë¦¬ (ì ë‹¹íˆ)
    cleanup_memory_if_needed()

    # ì„¸ì…˜ ìƒíƒœ ë©”ëª¨ë¦¬ ê´€ë¦¬ (ì ë‹¹íˆ)
    if "messages" in st.session_state and len(st.session_state.messages) > 30:
        # ì˜¤ë˜ëœ ë©”ì‹œì§€ ì œê±° (ìµœì‹  15ê°œ ìœ ì§€)
        st.session_state.messages = st.session_state.messages[-15:]
        logger.info("ì„¸ì…˜ ë©”ì‹œì§€ ì •ë¦¬ ì™„ë£Œ (ìµœì‹  15ê°œ ìœ ì§€)")

    # Render the simple ChatGPT UI and get user inputs
    user_input, area_input, uploaded_file = render_simple_chatgpt_ui()

    # ìƒˆë¡œìš´ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
    current_file_info = None
    if uploaded_file is not None:
        current_file_info = {
            "name": uploaded_file.name,
            "size": uploaded_file.size,
            "type": uploaded_file.type,
        }

    # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì¸ì§€ í™•ì¸
    is_same_file = (
        current_file_info is not None
        and st.session_state.last_processed_file is not None
        and current_file_info == st.session_state.last_processed_file
    )

    # Process text input
    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€
        message_data = {
            "role": "user",
            "content": str(user_input),
            "timestamp": datetime.now(),
            "area": area_input,
        }

        # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if uploaded_file is not None:
            # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©
            image_size = len(uploaded_file.getvalue())
            message_data["image_name"] = uploaded_file.name
            message_data["image_size"] = image_size

        st.session_state.messages.append(message_data)

        # ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ê°€ ëª¨ë‘ ìˆëŠ” ê²½ìš°ë§Œ ë¶„ì„ ì‹¤í–‰
        if (
            uploaded_file is not None
            and not is_same_file
            and not st.session_state.analysis_running
        ):
            st.session_state.analysis_running = True  # ë¶„ì„ ì‹œì‘ í”Œë˜ê·¸ ì„¤ì •
            st.session_state.processing_done = True  # ì²˜ë¦¬ ì™„ë£Œ í”Œë˜ê·¸ ì„¤ì •

            # 1. íŒŒì¼ í˜•ì‹ ë° í¬ê¸° ê²€ì¦
            file_valid, file_message = validate_uploaded_file(uploaded_file)
            if not file_valid:
                st.error(file_message)
                st.session_state.analysis_running = False  # ë¶„ì„ ì™„ë£Œ í”Œë˜ê·¸ í•´ì œ
                st.stop()  # rerun ëŒ€ì‹  stop ì‚¬ìš©

            # 2. ì´ë¯¸ì§€ ë‚´ìš© ê²€ì¦ (ê±´ë¬¼ì¸ì§€ í™•ì¸)
            content_valid, content_message = validate_image_content(uploaded_file)
            if not content_valid:
                st.error(content_message)
                st.session_state.analysis_running = False  # ë¶„ì„ ì™„ë£Œ í”Œë˜ê·¸ í•´ì œ
                st.stop()

            # 3. ë©´ì  ì…ë ¥ ê²€ì¦
            area_valid, area_message = validate_area_input(area_input)
            if not area_valid:
                st.error(area_message)
                st.session_state.analysis_running = False  # ë¶„ì„ ì™„ë£Œ í”Œë˜ê·¸ í•´ì œ
                st.stop()

            try:
                # ë¶„ì„ ì§„í–‰
                with st.spinner("ë¶„ì„ ì§„í–‰ ì¤‘..."):
                    memory_before = log_memory_usage("ë¶„ì„ ì‹œì‘ ì „")

                    # ë¶„ì„ ì „ ë©”ëª¨ë¦¬ ì •ë¦¬ (ì ë‹¹íˆ)
                    if memory_before > 600:
                        cleanup_memory_if_needed()

                    # Save the uploaded file
                    file_path = save_uploaded_file(
                        uploaded_file.getvalue(), uploaded_file.name, upload_dir
                    )

                    # í™˜ê²½ë³„ ìµœì í™”ëœ ë¶„ì„ ì‹¤í–‰
                    analysis_result = analysis_engine.generate_comprehensive_analysis(
                        image_path=str(file_path),
                        area=area_input,
                        user_message=str(user_input),
                    )

                    memory_after = log_memory_usage("ë¶„ì„ ì™„ë£Œ í›„")

                    # ë¶„ì„ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬ (ì ë‹¹íˆ)
                    if memory_after > 800:
                        cleanup_memory_if_needed()

                if analysis_result["success"]:
                    # ë¶„ì„ ì„±ê³µ
                    response_content = analysis_result["analysis_text"]

                    # PDF ë°ì´í„° ì¤€ë¹„ (êµ¬ì¡°í™”ëœ ë°ì´í„° í¬í•¨)
                    pdf_data = {
                        "analysis_result": analysis_result["analysis_text"],
                        "image_path": str(file_path),
                        "area": area_input,
                        "user_message": str(user_input),
                        "damage_areas": analysis_result["damage_areas"],
                    }

                    # Add the analysis result as assistant message
                    st.session_state.messages.append(
                        {
                            "role": "assistant",
                            "content": response_content,
                            "timestamp": datetime.now(),
                            "response_type": "comprehensive",
                            "pdf_data": pdf_data,
                        }
                    )

                    logger.info("ë¶„ì„ ì™„ë£Œ")

                    # ë©”ëª¨ë¦¬ ì •ë¦¬ (ì ë‹¹íˆ)
                    gc.collect()
                    try:
                        import torch

                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                    except ImportError:
                        pass

                    # ì²˜ë¦¬ëœ íŒŒì¼ ì •ë³´ ì €ì¥
                    if current_file_info:
                        st.session_state.last_processed_file = current_file_info

                    # ë¶„ì„ ì™„ë£Œ ì²˜ë¦¬
                    st.session_state.analysis_running = False
                    st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                    # í™”ë©´ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ê²°ê³¼ í‘œì‹œ
                    st.rerun()

                else:
                    # ë¶„ì„ ì‹¤íŒ¨
                    error_message = analysis_result.get(
                        "error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                    )
                    st.session_state.messages.append(
                        {
                            "role": "assistant",
                            "content": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_message}",
                            "timestamp": datetime.now(),
                            "response_type": "error",
                        }
                    )
                    st.session_state.analysis_running = False
                    st.rerun()

            except Exception as e:
                logger.error(f"Error processing file: {e}")
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.session_state.analysis_running = False
                st.session_state.processing_done = False

        elif uploaded_file is None:
            # í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€
            text_response = """
**ì•ˆë‚´**: ë” ì •í™•í•œ ê±´ë¬¼ í”¼í•´ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” í”¼í•´ ì‚¬ì§„ì„ ì²¨ë¶€í•´ì£¼ì„¸ìš”. 
ìœ„ì˜ íŒŒì¼ ì—…ë¡œë“œ ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•œ í›„ ë‹¤ì‹œ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•´ì£¼ì„¸ìš”.

**ì¼ë°˜ì ì¸ ê±´ë¬¼ í”¼í•´ ë¶„ì„ ì •ë³´**:
- êµ¬ì¡°ì  ê· ì—´: ë²½ì²´, ê¸°ë‘¥, ë³´ì˜ ê· ì—´ í™•ì¸
- ëˆ„ìˆ˜ í”¼í•´: ì§€ë¶•, ë²½ì²´ ì¹¨ìˆ˜ ì—¬ë¶€ ì ê²€  
- ì™¸ë¶€ ë§ˆê°ì¬: ì™¸ë²½, ì°½í˜¸ ì†ìƒ í™•ì¸
- ì„¤ë¹„ í”¼í•´: ì „ê¸°, ë°°ê´€ ì‹œì„¤ ì ê²€
            """

            st.session_state.messages.append(
                {
                    "role": "assistant",
                    "content": text_response,
                    "timestamp": datetime.now(),
                    "response_type": "text_only",
                }
            )
            st.info("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ë©´ AI ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

        elif is_same_file:
            st.info(
                "ì´ íŒŒì¼ì€ ì´ë¯¸ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
            )

    # ì´ë¯¸ì§€ë§Œ ì—…ë¡œë“œë˜ê³  ë©”ì‹œì§€ê°€ ì—†ëŠ” ê²½ìš°
    elif uploaded_file is not None and not user_input:
        st.info("ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ë¶„ì„ ìš”ì²­ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ê³  ì „ì†¡í•´ì£¼ì„¸ìš”.")

    # ë¶„ì„ì´ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš° ìƒíƒœ í‘œì‹œ
    elif st.session_state.analysis_running:
        st.info("ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")

    # ìƒˆ ì„¸ì…˜ ì‹œì‘ì„ ìœ„í•œ ë²„íŠ¼ ì¶”ê°€
    if st.session_state.processing_done:
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            if st.button("ìƒˆë¡œìš´ ë¶„ì„ ì‹œì‘", type="secondary"):
                # ìƒíƒœ ì´ˆê¸°í™”
                st.session_state.processing_done = False
                st.session_state.analysis_running = False
                st.session_state.last_processed_file = None
                st.success("ìƒˆë¡œìš´ ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
                # rerun ì—†ì´ ìƒíƒœë§Œ ì´ˆê¸°í™”


if __name__ == "__main__":
    main()
