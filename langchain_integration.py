"""
LangChain integration for building damage analysis - Performance Optimized
"""

import torch
from PIL import Image
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Any, Union
import logging
import json
from datetime import datetime
import functools
import time
from concurrent.futures import ThreadPoolExecutor
import asyncio

from langchain.chains.base import Chain
from langchain.schema import BaseOutputParser
from langchain.prompts import PromptTemplate
from langchain.llms.base import LLM
from langchain.memory import ConversationBufferMemory
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field, PrivateAttr

from models import BuildingDamageAnalysisModel
from config import DAMAGE_CATEGORIES, MODELS_DIR
import cv2

logger = logging.getLogger(__name__)

# Performance optimization: Thread pool for async operations
_thread_pool = ThreadPoolExecutor(max_workers=2)

# Cache for model predictions
_prediction_cache = {}


def performance_timer(func):
    """Decorator to measure function execution time"""

    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        logger.info(f"{func.__name__} executed in {end_time - start_time:.2f} seconds")
        return result

    return wrapper


class DamageAnalysisOutput(BaseModel):
    """Enhanced structured output for damage analysis"""

    damage_id: str = Field(description="Unique identifier for this damage analysis")
    image_metadata: Dict[str, Any] = Field(description="Image metadata information")
    damage_analysis: Dict[str, Any] = Field(
        description="Detailed damage analysis results"
    )
    recommendations: Dict[str, Any] = Field(
        description="Repair recommendations and actions"
    )
    cost_analysis: Dict[str, Any] = Field(
        description="Detailed cost breakdown and estimates"
    )
    repair_specifications: Dict[str, Any] = Field(
        description="Detailed repair specifications and methods"
    )
    confidence_score: float = Field(description="Overall confidence score (0-1)")
    timestamp: str = Field(description="Analysis timestamp")


class DamageAnalysisOutputParser(BaseOutputParser[DamageAnalysisOutput]):
    """Enhanced parser for damage analysis output"""

    @performance_timer
    def parse(self, text: str) -> DamageAnalysisOutput:
        """Parse the LLM output into structured format"""
        try:
            # Try to parse as JSON first
            if text.strip().startswith("{"):
                data = json.loads(text)
                return DamageAnalysisOutput(**data)

            # If not JSON, create structured output from text
            return self._parse_text_output(text)

        except Exception as e:
            logger.error(f"Error parsing output: {e}")
            return self._create_default_output(text)

    def _parse_text_output(self, text: str) -> DamageAnalysisOutput:
        """Parse text output into enhanced structured format"""

        # Extract key information using simple text parsing
        lines = text.split("\n")

        damage_analysis = {
            "primary_damage_type": "Unknown",
            "damage_types": [],
            "affected_areas": [],
            "severity_score": 1,
            "confidence_level": 0.5,
            "detailed_findings": text,
            "structural_impact": "ë¯¸í™•ì¸",
            "safety_risk_level": "ë³´í†µ",
        }

        recommendations = {
            "immediate_actions": [],
            "repair_priority": "medium",
            "safety_concerns": [],
            "repair_timeline": "1-2ì£¼",
            "professional_consultation": False,
        }

        cost_analysis = {
            "material_cost": 0,
            "labor_cost": 0,
            "equipment_cost": 0,
            "total_cost": 0,
            "cost_per_sqm": 0,
            "cost_breakdown": {},
        }

        repair_specifications = {
            "repair_methods": [],
            "required_materials": [],
            "required_equipment": [],
            "labor_requirements": {},
            "construction_standards": "ê±´ì„¤ê³µì‚¬ í‘œì¤€í’ˆì…ˆ 2024",
            "quality_standards": [],
        }

        # Simple keyword extraction
        text_lower = text.lower()

        # Extract severity
        if any(
            word in text_lower
            for word in ["ì‹¬ê°", "ìœ„í—˜", "critical", "severe", "ê¸´ê¸‰"]
        ):
            damage_analysis["severity_score"] = 4
            damage_analysis["safety_risk_level"] = "ë†’ìŒ"
            recommendations["professional_consultation"] = True
        elif any(word in text_lower for word in ["ë³´í†µ", "moderate", "ì¤‘ê°„"]):
            damage_analysis["severity_score"] = 3
            damage_analysis["safety_risk_level"] = "ë³´í†µ"
        elif any(word in text_lower for word in ["ê²½ë¯¸", "minor", "ê°€ë²¼ìš´"]):
            damage_analysis["severity_score"] = 2
            damage_analysis["safety_risk_level"] = "ë‚®ìŒ"

        # Extract damage types
        for damage_type in DAMAGE_CATEGORIES["damage_types"]:
            keywords = damage_type.lower().split()
            if any(keyword in text_lower for keyword in keywords):
                damage_analysis["primary_damage_type"] = damage_type
                damage_analysis["damage_types"].append(damage_type)

        # Extract affected areas
        for area in DAMAGE_CATEGORIES["affected_areas"]:
            if area.lower() in text_lower:
                damage_analysis["affected_areas"].append(area)

        return DamageAnalysisOutput(
            damage_id=f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            image_metadata={"source": "uploaded_image"},
            damage_analysis=damage_analysis,
            recommendations=recommendations,
            cost_analysis=cost_analysis,
            repair_specifications=repair_specifications,
            confidence_score=0.7,
            timestamp=datetime.now().isoformat(),
        )

    def _create_default_output(self, text: str) -> DamageAnalysisOutput:
        """Create enhanced default output when parsing fails"""

        return DamageAnalysisOutput(
            damage_id=f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            image_metadata={"source": "uploaded_image"},
            damage_analysis={
                "primary_damage_type": "Unknown",
                "damage_types": [],
                "affected_areas": [],
                "severity_score": 1,
                "confidence_level": 0.3,
                "detailed_findings": text,
                "structural_impact": "ë¯¸í™•ì¸",
                "safety_risk_level": "ë¯¸í™•ì¸",
            },
            recommendations={
                "immediate_actions": ["ì „ë¬¸ê°€ ê²€í†  í•„ìš”"],
                "repair_priority": "medium",
                "safety_concerns": ["ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ì¶”ê°€ ê²€ì‚¬ í•„ìš”"],
                "repair_timeline": "ì „ë¬¸ê°€ ìƒë‹´ í›„ ê²°ì •",
                "professional_consultation": True,
            },
            cost_analysis={
                "material_cost": 0,
                "labor_cost": 0,
                "equipment_cost": 0,
                "total_cost": 0,
                "cost_per_sqm": 0,
                "cost_breakdown": {"ë¶„ì„ ì‹¤íŒ¨": "ë¹„ìš© ì‚°ì • ë¶ˆê°€"},
            },
            repair_specifications={
                "repair_methods": ["ì „ë¬¸ê°€ ì§„ë‹¨ í•„ìš”"],
                "required_materials": [],
                "required_equipment": [],
                "labor_requirements": {},
                "construction_standards": "ê±´ì„¤ê³µì‚¬ í‘œì¤€í’ˆì…ˆ 2024",
                "quality_standards": ["ì „ë¬¸ê°€ ê²€í†  í•„ìš”"],
            },
            confidence_score=0.3,
            timestamp=datetime.now().isoformat(),
        )


class BuildingDamageLLM(LLM):
    """Enhanced custom LLM wrapper for building damage analysis model"""

    # Use PrivateAttr to avoid LangChain field validation
    _model: Any = PrivateAttr(default=None)
    _device: str = PrivateAttr(default="cpu")
    _current_image: Optional[Image.Image] = PrivateAttr(default=None)
    _model_path: Optional[Path] = PrivateAttr(default=None)

    def __init__(self, model_path: Optional[Path] = None, device: str = "cpu"):
        super().__init__()
        self._device = device
        self._model_path = model_path
        self._load_model()

    @performance_timer
    def _load_model(self):
        """Load the damage analysis model with performance optimization"""
        try:
            if self._model_path and self._model_path.exists():
                logger.info(f"Loading model from {self._model_path}")
                self._model = BuildingDamageAnalysisModel.load_model(
                    self._model_path, self._device
                )
            else:
                logger.info("Creating new model instance")
                self._model = BuildingDamageAnalysisModel()
                self._model.to(self._device)

            self._model.eval()
            logger.info("Model loaded successfully")

        except Exception as e:
            logger.error(f"Failed to load model: {e}")
            self._model = None

    def set_image(self, image_path: Union[str, Path]):
        """Set image for analysis with caching"""
        try:
            # Check cache first
            cache_key = str(image_path)
            if cache_key in _prediction_cache:
                logger.info("Using cached image")
                return

            image = Image.open(image_path)
            if image.mode != "RGB":
                image = image.convert("RGB")
            self._current_image = image
            logger.info(f"Image set successfully: {image.size}")

        except Exception as e:
            logger.error(f"Failed to set image: {e}")
            self._current_image = None

    def _preprocess_image(self, image: Image.Image) -> torch.Tensor:
        """Preprocess image for model input with optimization"""
        try:
            # Resize image for faster processing while maintaining quality
            max_size = 512
            if max(image.size) > max_size:
                ratio = max_size / max(image.size)
                new_size = tuple(int(dim * ratio) for dim in image.size)
                image = image.resize(new_size, Image.Resampling.LANCZOS)

            # Convert to tensor
            image_array = np.array(image)
            image_tensor = torch.from_numpy(image_array).float()

            # Normalize
            image_tensor = image_tensor / 255.0

            # Rearrange dimensions: (H, W, C) -> (C, H, W)
            image_tensor = image_tensor.permute(2, 0, 1)

            # Add batch dimension: (C, H, W) -> (1, C, H, W)
            image_tensor = image_tensor.unsqueeze(0)

            return image_tensor.to(self._device)

        except Exception as e:
            logger.error(f"Image preprocessing failed: {e}")
            raise

    @property
    def _llm_type(self) -> str:
        return "building_damage_analysis_enhanced"

    @performance_timer
    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        """Generate enhanced response for the given prompt"""

        if self._current_image is None:
            return "ì˜¤ë¥˜: ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_image() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."

        try:
            # Check cache first
            cache_key = f"{id(self._current_image)}_{hash(prompt)}"
            if cache_key in _prediction_cache:
                logger.info("Using cached prediction")
                return _prediction_cache[cache_key]

            # Preprocess image
            image_tensor = self._preprocess_image(self._current_image)

            # Get model predictions
            with torch.no_grad():
                predictions = self._model.get_damage_predictions(
                    image_tensor, [prompt], threshold=0.3
                )

            if predictions:
                prediction = predictions[0]

                # Format the enhanced response
                response = self._format_enhanced_analysis_response(prediction, prompt)

                # Cache the result
                _prediction_cache[cache_key] = response

                return response
            else:
                return "ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        except Exception as e:
            logger.error(f"Error in damage analysis: {e}")
            return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def _format_enhanced_analysis_response(
        self, prediction: Dict[str, Any], prompt: str
    ) -> str:
        """Format the model prediction into an enhanced readable response"""

        severity_level = prediction["severity_level"]
        severity_desc = prediction["severity_description"]
        damage_types = prediction["damage_types"]
        affected_areas = prediction["affected_areas"]
        confidence = prediction["severity_confidence"]

        # Enhanced response with more detailed information
        response = f"""
# ğŸ—ï¸ ê±´ë¬¼ í”¼í•´ ë¶„ì„ ìƒì„¸ ë³´ê³ ì„œ

## ğŸ“Š ë¶„ì„ ê°œìš”
- **ë¶„ì„ ID**: {datetime.now().strftime('ANA-%Y%m%d-%H%M%S')}
- **ë¶„ì„ ì‹œê°„**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}
- **ì‹ ë¢°ë„**: {confidence:.1%}

## ğŸ” í”¼í•´ í˜„í™© ë¶„ì„

### ğŸš¨ í”¼í•´ ì‹¬ê°ë„
- **ë“±ê¸‰**: {severity_level}/5
- **ì„¤ëª…**: {severity_desc}
- **êµ¬ì¡°ì  ì˜í–¥**: {self._assess_structural_impact(severity_level)}

### ğŸ  í”¼í•´ ìœ í˜• ë° ì˜ì—­
{self._format_damage_details(damage_types, affected_areas)}

## ğŸ”§ ë³µêµ¬ ë°©ë²• ë° ì‚¬ì–‘

### ğŸ“‹ ê¶Œì¥ ë³µêµ¬ ë°©ë²•
{self._generate_enhanced_recommendations(severity_level, damage_types)}

### ğŸ› ï¸ í•„ìš” ìì¬ ë° ì¥ë¹„
{self._generate_material_equipment_list(damage_types)}

### ğŸ‘· ì¸ë ¥ êµ¬ì„±
{self._generate_labor_requirements(severity_level, damage_types)}

## ğŸ’° ë¹„ìš© ë¶„ì„
{self._generate_cost_analysis(severity_level, damage_types)}

## âš ï¸ ì•ˆì „ ë° í’ˆì§ˆ ê´€ë¦¬
{self._generate_enhanced_safety_warnings(severity_level)}

## ğŸ“‹ ì ìš© ê¸°ì¤€
- **ê±´ì„¤ê³µì‚¬ í‘œì¤€í’ˆì…ˆ**: 2024ë…„ ê¸°ì¤€
- **ê±´ì¶•ë²•**: í˜„í–‰ ê±´ì¶•ë²• ë° ì‹œí–‰ë ¹
- **KS ê¸°ì¤€**: í•´ë‹¹ ìì¬ ë° ê³µë²• ê´€ë ¨ KS ê¸°ì¤€

---
*ë¶„ì„ ê¸°ì¤€: {prompt}*
*ë¶„ì„ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*ì‹œìŠ¤í…œ: Tumblr AI v2.0 Enhanced*
        """.strip()

        return response

    def _assess_structural_impact(self, severity_level: int) -> str:
        """Assess structural impact based on severity"""
        impact_levels = {
            1: "êµ¬ì¡°ì  ì˜í–¥ ì—†ìŒ",
            2: "ê²½ë¯¸í•œ êµ¬ì¡°ì  ì˜í–¥",
            3: "ë³´í†µ ìˆ˜ì¤€ì˜ êµ¬ì¡°ì  ì˜í–¥",
            4: "ì‹¬ê°í•œ êµ¬ì¡°ì  ì˜í–¥ ê°€ëŠ¥ì„±",
            5: "ë§¤ìš° ì‹¬ê°í•œ êµ¬ì¡°ì  ìœ„í—˜",
        }
        return impact_levels.get(severity_level, "êµ¬ì¡°ì  ì˜í–¥ ë¯¸í™•ì¸")

    def _format_damage_details(
        self, damage_types: List[str], affected_areas: List[str]
    ) -> str:
        """Format detailed damage information"""
        details = []

        if damage_types:
            details.append("**í”¼í•´ ìœ í˜•:**")
            for i, damage_type in enumerate(damage_types, 1):
                details.append(f"  {i}. {damage_type}")
        else:
            details.append("**í”¼í•´ ìœ í˜•:** íŠ¹ì • í”¼í•´ ìœ í˜•ì„ ì‹ë³„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if affected_areas:
            details.append("\n**ì˜í–¥ ë°›ì€ ì˜ì—­:**")
            for i, area in enumerate(affected_areas, 1):
                details.append(f"  {i}. {area}")
        else:
            details.append("\n**ì˜í–¥ ë°›ì€ ì˜ì—­:** íŠ¹ì • ì˜ì—­ì„ ì‹ë³„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        return "\n".join(details)

    def _generate_enhanced_recommendations(
        self, severity_level: int, damage_types: List[str]
    ) -> str:
        """Generate enhanced repair recommendations"""
        recommendations = []

        # Base recommendations by damage type
        repair_methods = {
            "ê· ì—´": [
                "ê· ì—´ ë¶€ìœ„ ì •ë°€ ì¡°ì‚¬ ë° ì›ì¸ ë¶„ì„",
                "ê· ì—´ í­ ë° ê¹Šì´ ì¸¡ì •",
                "ì—í­ì‹œ ìˆ˜ì§€ ì£¼ì… ë˜ëŠ” ì‹¤ë§ ì²˜ë¦¬",
                "í‘œë©´ ë§ˆê° ë³µêµ¬",
            ],
            "ëˆ„ìˆ˜": [
                "ëˆ„ìˆ˜ ê²½ë¡œ ì¶”ì  ë° ì›ì¸ íŒŒì•…",
                "ê¸°ì¡´ ë°©ìˆ˜ì¸µ ìƒíƒœ ì ê²€",
                "ë°©ìˆ˜ì¸µ ë³´ìˆ˜ ë˜ëŠ” ì¬ì‹œê³µ",
                "ë°°ìˆ˜ ì‹œì„¤ ì ê²€ ë° ê°œì„ ",
            ],
            "í™”ì¬": [
                "í™”ì¬ ì†ìƒ ë²”ìœ„ ì •ë°€ ì¡°ì‚¬",
                "êµ¬ì¡° ì•ˆì „ì„± ê²€í† ",
                "ì†ìƒ ë¶€ì¬ êµì²´ ë˜ëŠ” ë³´ê°•",
                "ë‚´í™” ì„±ëŠ¥ ë³µêµ¬",
            ],
        }

        primary_damage = damage_types[0] if damage_types else "ì¼ë°˜"
        methods = repair_methods.get(primary_damage, ["ì „ë¬¸ê°€ ì§„ë‹¨ í›„ ê²°ì •"])

        for i, method in enumerate(methods, 1):
            recommendations.append(f"{i}. {method}")

        return "\n".join(recommendations)

    def _generate_material_equipment_list(self, damage_types: List[str]) -> str:
        """Generate detailed material and equipment list"""
        materials = {
            "ê· ì—´": ["ì—í­ì‹œ ìˆ˜ì§€", "í”„ë¼ì´ë¨¸", "ì‹¤ë§ì¬", "ë³´ìˆ˜ ëª¨ë¥´íƒ€ë¥´"],
            "ëˆ„ìˆ˜": ["ë°©ìˆ˜ ì‹œíŠ¸", "ìš°ë ˆíƒ„ ë°©ìˆ˜ì¬", "ì‹¤ë¦¬ì½˜ ì‹¤ë€íŠ¸", "ë°°ìˆ˜ì¬"],
            "í™”ì¬": ["ë‚´í™”ì¬", "ë‹¨ì—´ì¬", "êµ¬ì¡°ìš© ê°•ì¬", "ë‚´í™” ë„ë£Œ"],
        }

        equipment = {
            "ê· ì—´": ["ì£¼ì…ê¸°", "ì••ì¶•ê¸°", "ê·¸ë¼ì¸ë”", "ì²­ì†Œ ì¥ë¹„"],
            "ëˆ„ìˆ˜": ["í† ì¹˜", "ë¡¤ëŸ¬", "ì••ì°©ê¸°", "ê±´ì¡° ì¥ë¹„"],
            "í™”ì¬": ["ì ˆë‹¨ê¸°", "ìš©ì ‘ê¸°", "í¬ë ˆì¸", "ì•ˆì „ ì¥ë¹„"],
        }

        primary_damage = damage_types[0] if damage_types else "ì¼ë°˜"

        result = "**ì£¼ìš” ìì¬:**\n"
        for i, material in enumerate(
            materials.get(primary_damage, ["ì „ë¬¸ê°€ ìƒë‹´ í•„ìš”"]), 1
        ):
            result += f"  {i}. {material}\n"

        result += "\n**í•„ìš” ì¥ë¹„:**\n"
        for i, equip in enumerate(
            equipment.get(primary_damage, ["ì „ë¬¸ê°€ ìƒë‹´ í•„ìš”"]), 1
        ):
            result += f"  {i}. {equip}\n"

        return result

    def _generate_labor_requirements(
        self, severity_level: int, damage_types: List[str]
    ) -> str:
        """Generate detailed labor requirements"""
        base_labor = {"íŠ¹ê¸‰ê¸°ëŠ¥ì‚¬": 1, "ê³ ê¸‰ê¸°ëŠ¥ì‚¬": 1, "ë³´í†µì¸ë¶€": 2}

        # Adjust based on severity
        if severity_level >= 4:
            base_labor["íŠ¹ê¸‰ê¸°ëŠ¥ì‚¬"] += 1
            base_labor["ê³ ê¸‰ê¸°ëŠ¥ì‚¬"] += 1

        result = "**ì¸ë ¥ êµ¬ì„±:**\n"
        for job_type, count in base_labor.items():
            result += f"  - {job_type}: {count}ëª…\n"

        return result

    def _generate_cost_analysis(
        self, severity_level: int, damage_types: List[str]
    ) -> str:
        """Generate detailed cost analysis"""
        base_costs = {
            "ê· ì—´": {"material": 25000, "labor": 15000},
            "ëˆ„ìˆ˜": {"material": 35000, "labor": 20000},
            "í™”ì¬": {"material": 80000, "labor": 40000},
        }

        primary_damage = damage_types[0] if damage_types else "ì¼ë°˜"
        costs = base_costs.get(primary_damage, {"material": 30000, "labor": 18000})

        # Adjust based on severity
        multiplier = 1 + (severity_level - 1) * 0.2

        material_cost = costs["material"] * multiplier
        labor_cost = costs["labor"] * multiplier
        total_cost = material_cost + labor_cost

        result = f"""**ë¹„ìš© êµ¬ì„± (mÂ²ë‹¹):**
  - ìì¬ë¹„: {material_cost:,.0f}ì›
  - ë…¸ë¬´ë¹„: {labor_cost:,.0f}ì›
  - ì´ ë‹¨ê°€: {total_cost:,.0f}ì›

**ë¹„ìš© ì‚°ì • ê¸°ì¤€:**
  - ê±´ì„¤ê³µì‚¬ í‘œì¤€í’ˆì…ˆ 2024ë…„ ê¸°ì¤€
  - ì¼ë°˜ì ì¸ ì‹œì¥ ë‹¨ê°€ ì ìš©
  - í˜„ì¥ ì—¬ê±´ì— ë”°ë¼ Â±20% ë³€ë™ ê°€ëŠ¥"""

        return result

    def _generate_enhanced_safety_warnings(self, severity_level: int) -> str:
        """Generate enhanced safety warnings"""
        warnings = []

        if severity_level >= 4:
            warnings.extend(
                [
                    "ğŸš¨ **ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”**",
                    "  - í•´ë‹¹ ì˜ì—­ ì¶œì… ê¸ˆì§€",
                    "  - êµ¬ì¡° ì—”ì§€ë‹ˆì–´ ê¸´ê¸‰ ì§„ë‹¨",
                    "  - ì„ì‹œ ë³´ê°• ì¡°ì¹˜ ê²€í† ",
                    "",
                    "âš ï¸ **ì•ˆì „ ê´€ë¦¬**",
                    "  - ì‘ì—…ì ì•ˆì „êµìœ¡ í•„ìˆ˜",
                    "  - ê°œì¸ë³´í˜¸êµ¬ ì°©ìš© ì˜ë¬´",
                    "  - ì•ˆì „ê´€ë¦¬ì ìƒì£¼",
                ]
            )
        elif severity_level >= 3:
            warnings.extend(
                [
                    "âš ï¸ **ì£¼ì˜ ê¹Šì€ ê´€ë¦¬**",
                    "  - ì •ê¸°ì  ì•ˆì „ ì ê²€",
                    "  - ì‘ì—… ì¤‘ ì•ˆì „ í™•ë³´",
                    "  - ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§",
                    "",
                    "ğŸ” **í’ˆì§ˆ ê´€ë¦¬**",
                    "  - ì‹œê³µ í’ˆì§ˆ ê²€ì‚¬",
                    "  - ìì¬ í’ˆì§ˆ í™•ì¸",
                    "  - ì™„ë£Œ í›„ ì„±ëŠ¥ ê²€ì¦",
                ]
            )
        else:
            warnings.extend(
                [
                    "âœ… **ì¼ë°˜ ì•ˆì „ ê´€ë¦¬**",
                    "  - ê¸°ë³¸ ì•ˆì „ìˆ˜ì¹™ ì¤€ìˆ˜",
                    "  - ì •ê¸° ì ê²€ ì‹¤ì‹œ",
                    "  - ì˜ˆë°©ì  ìœ ì§€ê´€ë¦¬",
                ]
            )

        return "\n".join(warnings)


class ImageAnalysisChain(Chain):
    """LangChain for image-based damage analysis"""

    # Use PrivateAttr to avoid LangChain field validation
    _llm: Any = PrivateAttr(default=None)
    _prompt_template: Any = PrivateAttr(default=None)
    _output_parser: Any = PrivateAttr(default=None)

    @property
    def input_keys(self) -> List[str]:
        return ["image_path", "query"]

    @property
    def output_keys(self) -> List[str]:
        return ["analysis_result"]

    def __init__(
        self, model_path: Optional[Path] = None, device: str = "cpu", **kwargs
    ):
        super().__init__(**kwargs)

        # Initialize the custom LLM
        self._llm = BuildingDamageLLM(model_path, device)

        # Create prompt template
        self._prompt_template = PromptTemplate(
            input_variables=["query"],
            template="""
ê±´ë¬¼ í”¼í•´ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.

ë¶„ì„ ìš”ì²­: {query}

ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ì‚¬í•­ë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. í”¼í•´ì˜ ì‹¬ê°ë„ (1-5 ë“±ê¸‰)
2. í”¼í•´ ìœ í˜• ì‹ë³„
3. ì˜í–¥ì„ ë°›ì€ ê±´ë¬¼ ì˜ì—­
4. ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­
5. ì•ˆì „ ì£¼ì˜ì‚¬í•­

ìƒì„¸í•˜ê³  ì „ë¬¸ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.
            """.strip(),
        )

        # Output parser
        self._output_parser = DamageAnalysisOutputParser()

    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Execute the chain"""

        image_path = inputs["image_path"]
        query = inputs.get("query", "ê±´ë¬¼ì˜ í”¼í•´ ìƒí™©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.")

        try:
            # Set the image for analysis
            self._llm.set_image(image_path)

            # Format the prompt
            formatted_prompt = self._prompt_template.format(query=query)

            # Get analysis result
            analysis_text = self._llm(formatted_prompt)

            # Parse the output
            parsed_result = self._output_parser.parse(analysis_text)

            return {"analysis_result": parsed_result}

        except Exception as e:
            logger.error(f"Error in ImageAnalysisChain: {e}")

            # Return error result
            error_result = DamageAnalysisOutput(
                damage_id=f"error_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                image_metadata={"source": str(image_path), "error": str(e)},
                damage_analysis={
                    "primary_damage_type": "Analysis Failed",
                    "affected_areas": [],
                    "severity_score": 0,
                    "confidence_level": 0.0,
                    "detailed_findings": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                },
                recommendations={
                    "immediate_actions": ["ìˆ˜ë™ ê²€ì‚¬ í•„ìš”"],
                    "repair_priority": "unknown",
                    "safety_concerns": ["ë¶„ì„ ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ìˆ˜ë™ ê²€ì‚¬ í•„ìš”"],
                },
                confidence_score=0.0,
                timestamp=datetime.now().isoformat(),
            )

            return {"analysis_result": error_result}


class ReportGenerationChain(Chain):
    """Chain for generating comprehensive damage reports"""

    # Use PrivateAttr to avoid LangChain field validation
    _report_template: str = PrivateAttr(default="")

    @property
    def input_keys(self) -> List[str]:
        return ["analysis_result", "additional_info"]

    @property
    def output_keys(self) -> List[str]:
        return ["report"]

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

        self._report_template = """
# ê±´ë¬¼ í”¼í•´ ë¶„ì„ ì¢…í•© ë³´ê³ ì„œ

## ë¶„ì„ ê°œìš”
- **ë¶„ì„ ID**: {damage_id}
- **ë¶„ì„ ì¼ì‹œ**: {timestamp}
- **ì „ì²´ ì‹ ë¢°ë„**: {confidence_score:.1%}

## í”¼í•´ í˜„í™© ìš”ì•½
### ì£¼ìš” í”¼í•´ ìœ í˜•
{primary_damage_type}

### í”¼í•´ ì‹¬ê°ë„
- **ë“±ê¸‰**: {severity_score}/5
- **ì„¤ëª…**: {severity_description}

### ì˜í–¥ ë°›ì€ ì˜ì—­
{affected_areas}

## ìƒì„¸ ë¶„ì„ ê²°ê³¼
{detailed_findings}

## ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­
### ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­
{immediate_actions}

### ë³´ìˆ˜ ìš°ì„ ìˆœìœ„
{repair_priority}

### ì•ˆì „ ì£¼ì˜ì‚¬í•­
{safety_concerns}

## ì¶”ê°€ ì •ë³´
{additional_info}

---
*ë³¸ ë³´ê³ ì„œëŠ” AI ê¸°ë°˜ ìë™ ë¶„ì„ ì‹œìŠ¤í…œì— ì˜í•´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
*ì •í™•í•œ ì§„ë‹¨ì„ ìœ„í•´ì„œëŠ” ì „ë¬¸ê°€ì˜ í˜„ì¥ ê²€ì‚¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.*
        """

    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Generate comprehensive report"""

        analysis_result = inputs["analysis_result"]
        additional_info = inputs.get("additional_info", "ì¶”ê°€ ì •ë³´ ì—†ìŒ")

        if isinstance(analysis_result, DamageAnalysisOutput):
            # Extract data from structured output
            damage_analysis = analysis_result.damage_analysis
            recommendations = analysis_result.recommendations

            # Format the report
            report = self._report_template.format(
                damage_id=analysis_result.damage_id,
                timestamp=analysis_result.timestamp,
                confidence_score=analysis_result.confidence_score,
                primary_damage_type=damage_analysis.get(
                    "primary_damage_type", "Unknown"
                ),
                severity_score=damage_analysis.get("severity_score", 0),
                severity_description=f"{damage_analysis.get('severity_score', 0)}/5 ë“±ê¸‰",
                affected_areas=self._format_list(
                    damage_analysis.get("affected_areas", [])
                ),
                detailed_findings=damage_analysis.get(
                    "detailed_findings", "ìƒì„¸ ë¶„ì„ ì •ë³´ ì—†ìŒ"
                ),
                immediate_actions=self._format_list(
                    recommendations.get("immediate_actions", [])
                ),
                repair_priority=recommendations.get("repair_priority", "unknown"),
                safety_concerns=self._format_list(
                    recommendations.get("safety_concerns", [])
                ),
                additional_info=additional_info,
            )
        else:
            # Handle string input
            report = f"""
# ê±´ë¬¼ í”¼í•´ ë¶„ì„ ë³´ê³ ì„œ

## ë¶„ì„ ê²°ê³¼
{analysis_result}

## ì¶”ê°€ ì •ë³´
{additional_info}

---
*ë¶„ì„ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
            """

        return {"report": report}

    def _format_list(self, items: List[str]) -> str:
        """Format list items"""
        if not items:
            return "- í•´ë‹¹ ì—†ìŒ"
        return "\n".join([f"- {item}" for item in items])


class ValidationChain(Chain):
    """Chain for validating analysis results"""

    @property
    def input_keys(self) -> List[str]:
        return ["analysis_result"]

    @property
    def output_keys(self) -> List[str]:
        return ["validation_result", "confidence_adjustment"]

    def __init__(self):
        super().__init__()

    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Validate analysis results"""

        analysis_result = inputs["analysis_result"]

        validation_checks = {
            "severity_consistency": True,
            "damage_type_validity": True,
            "area_consistency": True,
            "recommendation_appropriateness": True,
        }

        confidence_adjustment = 1.0
        issues = []

        if isinstance(analysis_result, DamageAnalysisOutput):
            damage_analysis = analysis_result.damage_analysis

            # Check severity consistency
            severity = damage_analysis.get("severity_score", 0)
            if severity < 1 or severity > 5:
                validation_checks["severity_consistency"] = False
                issues.append("ì‹¬ê°ë„ ë“±ê¸‰ì´ ìœ íš¨ ë²”ìœ„(1-5)ë¥¼ ë²—ì–´ë‚¨")
                confidence_adjustment *= 0.7

            # Check damage types
            damage_types = damage_analysis.get("damage_types", [])
            valid_types = DAMAGE_CATEGORIES["damage_types"]

            for damage_type in damage_types:
                if damage_type not in valid_types:
                    validation_checks["damage_type_validity"] = False
                    issues.append(f"ì•Œ ìˆ˜ ì—†ëŠ” í”¼í•´ ìœ í˜•: {damage_type}")
                    confidence_adjustment *= 0.8

        validation_result = {
            "is_valid": all(validation_checks.values()),
            "checks": validation_checks,
            "issues": issues,
            "overall_confidence": analysis_result.confidence_score
            * confidence_adjustment,
        }

        return {
            "validation_result": validation_result,
            "confidence_adjustment": confidence_adjustment,
        }


def create_damage_analysis_pipeline(
    model_path: Optional[Path] = None, device: str = "cpu"
) -> Dict[str, Chain]:
    """Create complete damage analysis pipeline"""

    # Create individual chains
    image_analysis_chain = ImageAnalysisChain(model_path, device)
    report_generation_chain = ReportGenerationChain()
    validation_chain = ValidationChain()

    return {
        "image_analysis": image_analysis_chain,
        "report_generation": report_generation_chain,
        "validation": validation_chain,
    }


def analyze_building_damage(
    image_path: Union[str, Path],
    query: str = "ê±´ë¬¼ì˜ í”¼í•´ ìƒí™©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.",
    model_path: Optional[Path] = None,
    device: str = "cpu",
    generate_report: bool = True,
) -> Dict[str, Any]:
    """
    Complete building damage analysis workflow

    Args:
        image_path: Path to the image to analyze
        query: Analysis query/request
        model_path: Path to trained model (optional)
        device: Device to run analysis on
        generate_report: Whether to generate comprehensive report

    Returns:
        Dictionary with analysis results
    """

    # Create pipeline
    pipeline = create_damage_analysis_pipeline(model_path, device)

    # Step 1: Image Analysis
    logger.info("Starting image analysis...")
    analysis_inputs = {"image_path": str(image_path), "query": query}

    analysis_output = pipeline["image_analysis"](analysis_inputs)
    analysis_result = analysis_output["analysis_result"]

    # Step 2: Validation
    logger.info("Validating analysis results...")
    validation_output = pipeline["validation"]({"analysis_result": analysis_result})
    validation_result = validation_output["validation_result"]

    # Step 3: Report Generation (if requested)
    report = None
    if generate_report:
        logger.info("Generating comprehensive report...")
        report_inputs = {
            "analysis_result": analysis_result,
            "additional_info": f"ê²€ì¦ ê²°ê³¼: {validation_result}",
        }
        report_output = pipeline["report_generation"](report_inputs)
        report = report_output["report"]

    return {
        "analysis_result": analysis_result,
        "validation_result": validation_result,
        "report": report,
        "success": validation_result["is_valid"],
    }


if __name__ == "__main__":
    # Test the LangChain integration
    import logging

    logging.basicConfig(level=logging.INFO)

    # Test with a sample image (if available)
    sample_image_path = Path("learning_pictures/1.jpg")

    if sample_image_path.exists():
        result = analyze_building_damage(
            image_path=sample_image_path,
            query="ì´ ê±´ë¬¼ì˜ í”¼í•´ ìƒí™©ì„ ìì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”.",
            device="cpu",
        )

        print("Analysis completed!")
        print(f"Success: {result['success']}")
        if result["report"]:
            print("\nGenerated Report:")
            print(result["report"])
    else:
        print(f"Sample image not found: {sample_image_path}")
        print("Please provide a valid image path for testing.")
