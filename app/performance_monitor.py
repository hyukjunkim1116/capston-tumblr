"""
ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìœ í‹¸ë¦¬í‹° - ë¡œì»¬ vs ë°°í¬ í™˜ê²½ ì„±ëŠ¥ ë¹„êµ
"""

import time
import logging
import psutil
import streamlit as st
from datetime import datetime
from typing import Dict, Any, List
from pathlib import Path
import json

logger = logging.getLogger(__name__)


class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë¹„êµ í´ë˜ìŠ¤"""

    def __init__(self):
        self.metrics = {}
        self.start_time = None
        self.memory_start = None

    def start_monitoring(self, operation_name: str):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.operation_name = operation_name
        self.start_time = time.time()
        self.memory_start = self._get_memory_usage()

        logger.info(f"ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘: {operation_name}")

    def end_monitoring(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ ë° ê²°ê³¼ ë°˜í™˜"""
        if not self.start_time:
            return {}

        end_time = time.time()
        memory_end = self._get_memory_usage()

        metrics = {
            "operation": self.operation_name,
            "duration": end_time - self.start_time,
            "memory_start_mb": self.memory_start,
            "memory_end_mb": memory_end,
            "memory_delta_mb": memory_end - self.memory_start,
            "timestamp": datetime.now().isoformat(),
        }

        # í™˜ê²½ ì •ë³´ ì¶”ê°€
        from app.config import get_app_config

        config = get_app_config()
        metrics.update(
            {
                "environment": config["environment"],
                "is_deployment": config["is_deployment"],
                "device": config["device"],
                "max_image_size": config["max_image_size"],
            }
        )

        logger.info(
            f"âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ: {self.operation_name} ({metrics['duration']:.2f}ì´ˆ)"
        )

        # ë©”íŠ¸ë¦­ ì €ì¥
        self._save_metrics(metrics)

        return metrics

    def _get_memory_usage(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"""
        try:
            process = psutil.Process()
            return process.memory_info().rss / 1024 / 1024
        except:
            return 0.0

    def _save_metrics(self, metrics: Dict[str, Any]):
        """ë©”íŠ¸ë¦­ì„ íŒŒì¼ì— ì €ì¥"""
        try:
            metrics_file = Path("cache/performance_metrics.jsonl")
            metrics_file.parent.mkdir(exist_ok=True)

            with open(metrics_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(metrics) + "\n")

        except Exception as e:
            logger.warning(f"âš ï¸ ë©”íŠ¸ë¦­ ì €ì¥ ì‹¤íŒ¨: {e}")


def performance_wrapper(operation_name: str):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""

    def decorator(func):
        def wrapper(*args, **kwargs):
            monitor = PerformanceMonitor()
            monitor.start_monitoring(operation_name)

            try:
                result = func(*args, **kwargs)
                return result
            finally:
                metrics = monitor.end_monitoring()

                # Streamlit ì„¸ì…˜ì— ë©”íŠ¸ë¦­ ì €ì¥
                if hasattr(st.session_state, "performance_metrics"):
                    st.session_state.performance_metrics.append(metrics)
                else:
                    st.session_state.performance_metrics = [metrics]

        return wrapper

    return decorator


@st.cache_data
def load_performance_history() -> List[Dict[str, Any]]:
    """ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ë¡œë“œ"""
    try:
        metrics_file = Path("cache/performance_metrics.jsonl")
        if not metrics_file.exists():
            return []

        metrics = []
        with open(metrics_file, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    metrics.append(json.loads(line.strip()))
                except:
                    continue

        return metrics[-100:]  # ìµœê·¼ 100ê°œë§Œ

    except Exception as e:
        logger.warning(f"âš ï¸ ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []


def display_performance_comparison():
    """ì„±ëŠ¥ ë¹„êµ ëŒ€ì‹œë³´ë“œ í‘œì‹œ"""
    st.subheader("ğŸ“Š ì„±ëŠ¥ ë¹„êµ ëŒ€ì‹œë³´ë“œ")

    history = load_performance_history()
    current_session = getattr(st.session_state, "performance_metrics", [])

    if not history and not current_session:
        st.info("ì•„ì§ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í™˜ê²½ë³„ ë°ì´í„° ë¶„ë¦¬
    local_metrics = [m for m in history if not m.get("is_deployment", False)]
    deployment_metrics = [m for m in history if m.get("is_deployment", False)]

    # ë¹„êµ í‘œ ìƒì„±
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### ğŸ’» ë¡œì»¬ í™˜ê²½")
        if local_metrics:
            avg_duration = sum(m["duration"] for m in local_metrics) / len(
                local_metrics
            )
            avg_memory = sum(m["memory_delta_mb"] for m in local_metrics) / len(
                local_metrics
            )

            st.metric("í‰ê·  ì²˜ë¦¬ ì‹œê°„", f"{avg_duration:.2f}ì´ˆ")
            st.metric("í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©", f"{avg_memory:.1f}MB")
            st.metric("ì´ ì‹¤í–‰ íšŸìˆ˜", len(local_metrics))
        else:
            st.info("ë¡œì»¬ í™˜ê²½ ë°ì´í„° ì—†ìŒ")

    with col2:
        st.markdown("### ğŸŒ ë°°í¬ í™˜ê²½")
        if deployment_metrics:
            avg_duration = sum(m["duration"] for m in deployment_metrics) / len(
                deployment_metrics
            )
            avg_memory = sum(m["memory_delta_mb"] for m in deployment_metrics) / len(
                deployment_metrics
            )

            st.metric("í‰ê·  ì²˜ë¦¬ ì‹œê°„", f"{avg_duration:.2f}ì´ˆ")
            st.metric("í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©", f"{avg_memory:.1f}MB")
            st.metric("ì´ ì‹¤í–‰ íšŸìˆ˜", len(deployment_metrics))
        else:
            st.info("ë°°í¬ í™˜ê²½ ë°ì´í„° ì—†ìŒ")

    # í˜„ì¬ ì„¸ì…˜ ì„±ëŠ¥
    if current_session:
        st.markdown("### ğŸ”„ í˜„ì¬ ì„¸ì…˜ ì„±ëŠ¥")
        latest = current_session[-1]

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ë§ˆì§€ë§‰ ì²˜ë¦¬ ì‹œê°„", f"{latest['duration']:.2f}ì´ˆ")
        with col2:
            st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", f"{latest['memory_delta_mb']:.1f}MB")
        with col3:
            env_emoji = "ğŸŒ" if latest["is_deployment"] else "ğŸ’»"
            st.metric("ì‹¤í–‰ í™˜ê²½", f"{env_emoji} {latest['environment']} (ê³ ì •í™•ë„)")


def get_performance_recommendations() -> List[str]:
    """ì„±ëŠ¥ ê¶Œì¥ì‚¬í•­ (ëª¨ë“  í™˜ê²½ì—ì„œ ê³ ì •í™•ë„ ì„¤ì •)"""
    from app.config import get_app_config

    config = get_app_config()

    recommendations = [
        "ğŸ¯ ëª¨ë“  í™˜ê²½ì—ì„œ ê³ ì •í™•ë„ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤",
        "âš¡ TTA(Test Time Augmentation)ê°€ í™œì„±í™”ë˜ì–´ ì •í™•ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤",
        "ğŸ“Š ë°°ì¹˜ í¬ê¸° 4ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤",
        "ğŸ”¥ ìµœê³  í’ˆì§ˆ GPT-4o ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤",
        "ğŸ“ ì´ë¯¸ì§€ ìµœëŒ€ í¬ê¸°: 2048pxë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤",
    ]

    if config["is_deployment"]:
        recommendations.append(
            "ğŸŒ ë°°í¬ í™˜ê²½ì—ì„œë„ ë¡œì»¬ê³¼ ë™ì¼í•œ ê³ ì •í™•ë„ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤"
        )
    else:
        recommendations.append("ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ìµœì ì˜ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤")

    return recommendations


# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì ìš©ì„ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def optimize_image_processing():
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ìµœì í™” (ëª¨ë“  í™˜ê²½ì—ì„œ ê³ ì„±ëŠ¥ ì„¤ì •)"""
    from app.config import get_app_config

    config = get_app_config()

    # ëª¨ë“  í™˜ê²½ì—ì„œ ê³ ì„±ëŠ¥ ì„¤ì •
    import torch

    if torch.cuda.is_available():
        torch.set_num_threads(8)  # ë” ë§ì€ CPU ìŠ¤ë ˆë“œ ì‚¬ìš©
        logger.info("ğŸš€ CUDA ê°€ì† ë° ë©€í‹°ìŠ¤ë ˆë”© ìµœì í™” ì ìš©")
    else:
        torch.set_num_threads(8)  # CPU í™˜ê²½ì—ì„œë„ ë©€í‹°ìŠ¤ë ˆë”©
        logger.info("ğŸ’» CPU ë©€í‹°ìŠ¤ë ˆë”© ìµœì í™” ì ìš©")

    if config["is_deployment"]:
        # ë°°í¬ í™˜ê²½ë„ ì´ì œ ê³ ì„±ëŠ¥ ì„¤ì • ì‚¬ìš© (ë©”ëª¨ë¦¬ ì •ë¦¬ë§Œ ìœ ì§€)
        import gc

        gc.collect()  # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        logger.info("ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
    else:
        logger.info("ğŸ’» ë¡œì»¬ í™˜ê²½ ì„¤ì • ìœ ì§€")

    logger.info(f"ğŸ¯ ê³ ì •í™•ë„ ëª¨ë“œ í™œì„±í™” - í™˜ê²½: {config['environment']}")


@st.cache_data
def get_system_info() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ"""
    try:
        return {
            "cpu_count": psutil.cpu_count(),
            "memory_total_gb": psutil.virtual_memory().total / 1024**3,
            "memory_available_gb": psutil.virtual_memory().available / 1024**3,
            "disk_free_gb": psutil.disk_usage(".").free / 1024**3,
        }
    except:
        return {"error": "ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨"}


def display_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ í‘œì‹œ"""
    st.subheader("ğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´")

    info = get_system_info()

    if "error" not in info:
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("CPU ì½”ì–´", f"{info['cpu_count']}ê°œ")
        with col2:
            st.metric("ì´ ë©”ëª¨ë¦¬", f"{info['memory_total_gb']:.1f}GB")
        with col3:
            st.metric("ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬", f"{info['memory_available_gb']:.1f}GB")
        with col4:
            st.metric("ë””ìŠ¤í¬ ì—¬ìœ ê³µê°„", f"{info['disk_free_gb']:.1f}GB")
    else:
        st.error("ì‹œìŠ¤í…œ ì •ë³´ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
