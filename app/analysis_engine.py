"""
AI ë¶„ì„ ì—”ì§„ ëª¨ë“ˆ - í™˜ê²½ë³„ ì„±ëŠ¥ ìµœì í™”
YOLOv8 + CLIP + GPT-4 íŒŒì´í”„ë¼ì¸
"""

import streamlit as st
import time
import logging
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, Any, List, Tuple
from PIL import Image, ImageDraw
import torch
import os
from openai import OpenAI
from datetime import datetime

# ë¡œê±° ë¨¼ì € ì •ì˜
logger = logging.getLogger(__name__)

# ì„¤ì • ë° í™˜ê²½ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
from app.config import get_app_config, IS_DEPLOYMENT, DEVICE, BATCH_SIZE, MAX_IMAGE_SIZE

# ì „ì—­ ì„¤ì •
APP_CONFIG = get_app_config()

# YOLOv8 ê´€ë ¨ - í™˜ê²½ë³„ ìµœì í™”
try:
    from ultralytics import YOLO

    YOLO_AVAILABLE = True
    logger.info("âœ… YOLOv8 íŒ¨í‚¤ì§€ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    YOLO_AVAILABLE = False
    logger.warning(f"âš ï¸ YOLOv8 not available: {e}")
except Exception as e:
    YOLO_AVAILABLE = False
    logger.warning(f"âš ï¸ YOLOv8 ë¡œë”© ì˜¤ë¥˜: {e}")

# CLIP ê´€ë ¨ - í™˜ê²½ë³„ ìµœì í™”
try:
    import clip

    CLIP_AVAILABLE = True
    logger.info("âœ… CLIP íŒ¨í‚¤ì§€ ë¡œë“œ ì„±ê³µ")
except ImportError:
    CLIP_AVAILABLE = False
    logger.warning("âš ï¸ CLIP not available")

# LangChain ê´€ë ¨ - ìµœì‹  íŒ¨í‚¤ì§€ë¡œ ì—…ë°ì´íŠ¸
try:
    from langchain_openai import OpenAI as LangChainOpenAI
    from langchain.prompts import PromptTemplate

    LANGCHAIN_AVAILABLE = True
    logger.info("âœ… LangChain íŒ¨í‚¤ì§€ ë¡œë“œ ì„±ê³µ")
except ImportError:
    try:
        from langchain_community.llms import OpenAI as LangChainOpenAI
        from langchain.prompts import PromptTemplate

        LANGCHAIN_AVAILABLE = True
        logger.info("âœ… LangChain Community íŒ¨í‚¤ì§€ ë¡œë“œ ì„±ê³µ")
    except ImportError:
        LANGCHAIN_AVAILABLE = False
        logger.warning("âš ï¸ LangChain not available")

# ìƒˆë¡œìš´ ê¸°ì¤€ ë°ì´í„° ë§¤ë‹ˆì € import
from app.criteria_loader import get_criteria_manager

# í”¼í•´ ìœ í˜• ë§¤í•‘ (CLIP ë¶„ë¥˜ìš©)
DAMAGE_TYPES = [
    "crack damage",
    "water damage",
    "fire damage",
    "roof damage",
    "window damage",
    "door damage",
    "foundation damage",
    "structural deformation",
    "facade damage",
    "normal building",
]

# í•œêµ­ì–´-ì˜ì–´ ë§¤í•‘
DAMAGE_TYPE_KR_MAP = {
    "crack damage": "ê· ì—´ í”¼í•´",
    "water damage": "ìˆ˜í•´ í”¼í•´",
    "fire damage": "í™”ì¬ í”¼í•´",
    "roof damage": "ì§€ë¶• í”¼í•´",
    "window damage": "ì°½ë¬¸ í”¼í•´",
    "door damage": "ë¬¸ í”¼í•´",
    "foundation damage": "ê¸°ì´ˆ í”¼í•´",
    "structural deformation": "êµ¬ì¡°ì  ë³€í˜•",
    "facade damage": "ì™¸ë²½ í”¼í•´",
    "normal building": "ì •ìƒ",
}


@st.cache_resource
def get_shared_models():
    """ì „ì—­ ê³µìœ  ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±"""
    from app.config import initialize_optimized_models

    return initialize_optimized_models()


class AnalysisEngine:
    """í†µí•© ë¶„ì„ ì—”ì§„ - í™˜ê²½ë³„ ìµœì í™”"""

    def __init__(self):
        """ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” - ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ê³ ì„±ëŠ¥ ì„¤ì •"""
        logger.info("ğŸš€ AnalysisEngine ì´ˆê¸°í™” ì‹œì‘")

        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        self.start_time = time.time()

        # ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ê³ ì„±ëŠ¥ ì„¤ì •
        self.config = APP_CONFIG
        self.device = DEVICE
        self.is_deployment = IS_DEPLOYMENT  # ë¡œê¹…ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©
        self.max_image_size = MAX_IMAGE_SIZE  # ëª¨ë“  í™˜ê²½ì—ì„œ 2048

        # ê³µìœ  ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© (ë©”ëª¨ë¦¬ ì ˆì•½)
        self.shared_models = get_shared_models()

        # ê° ëª¨ë“ˆ ì´ˆê¸°í™” (ëª¨ë¸ ì¬ì‚¬ìš©) - ëª¨ë“  í™˜ê²½ì—ì„œ ê³ ì„±ëŠ¥ ì„¤ì •
        self.yolo_model = OptimizedYOLODetector(self.shared_models.get("yolo"))
        self.clip_model = OptimizedCLIPClassifier(self.shared_models.get("clip"))
        self.gpt_model = OptimizedGPTGenerator(self.shared_models.get("openai"))

        # ë°ì´í„° í”„ë¡œì„¸ì„œ (ì´ë¯¸ì§€ ê²€ì¦ìš©)
        from app.data_processor import DataProcessor

        self.data_processor = DataProcessor()

        init_time = time.time() - self.start_time
        logger.info(
            f"âœ… AnalysisEngine ì´ˆê¸°í™” ì™„ë£Œ ({init_time:.2f}ì´ˆ) - í™˜ê²½: {self.device}"
        )
        logger.info("ğŸ¯ ì„¤ì •: ëª¨ë“  í™˜ê²½ì—ì„œ ì»¤ìŠ¤í…€ ëª¨ë¸ ì‚¬ìš© ê°•ì œ")

    @st.cache_data
    def generate_comprehensive_analysis(
        self, image_path: str, area: float, user_message: str = ""
    ) -> Dict[str, Any]:
        """ì¢…í•© ë¶„ì„ ì‹¤í–‰ - ìºì‹± ì ìš©"""
        try:
            logger.info("ğŸ” ì¢…í•© ë¶„ì„ ì‹œì‘")
            self.start_time = time.time()

            # ì´ë¯¸ì§€ ìµœì í™” ì „ì²˜ë¦¬
            processed_image_path = self._optimize_image_for_analysis(image_path)

            # 1. ì´ë¯¸ì§€ ê²€ì¦
            validation_result = self.data_processor.validate_image_content(
                processed_image_path
            )
            if not validation_result["is_valid"]:
                return {
                    "success": False,
                    "error": validation_result["error"],
                    "error_type": "validation_error",
                }

            # 2. YOLO í”¼í•´ íƒì§€ (ëª¨ë“  í™˜ê²½ì—ì„œ ê³ ì •í™•ë„ ì„¤ì •)
            yolo_result = self.yolo_model.detect_damage_areas(
                processed_image_path,
                use_tta=True,  # ëª¨ë“  í™˜ê²½ì—ì„œ TTA í™œì„±í™”
            )

            if not yolo_result:
                yolo_result = self._create_fallback_detection(processed_image_path)

            # 3. CLIP ë¶„ë¥˜ (ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”)
            clip_results = self.clip_model.classify_damage_areas_batch(
                processed_image_path, yolo_result
            )

            # ê²°ê³¼ í†µí•©
            for i, detection in enumerate(yolo_result):
                if i < len(clip_results):
                    best_damage_type = max(clip_results[i], key=clip_results[i].get)
                    detection["class"] = best_damage_type
                    detection["confidence"] = clip_results[i][best_damage_type]

            # 4. êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„±
            structured_data = self._create_structured_analysis_data(
                yolo_result, clip_results, area, user_message
            )

            # 5. í…ìŠ¤íŠ¸ ë¶„ì„ ìƒì„±
            text_analysis = self._generate_user_friendly_text(structured_data)

            processing_time = time.time() - self.start_time

            return {
                "success": True,
                "analysis_text": text_analysis,
                "structured_data": structured_data,
                "damage_areas": structured_data["damage_areas"],
                "yolo_detections": yolo_result,
                "clip_classifications": clip_results,
                "processing_time": processing_time,
                "environment": self.config["environment"],
                "optimizations_applied": self._get_optimization_summary(),
            }

        except Exception as e:
            logger.error(f"âŒ ì¢…í•© ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "error_type": "analysis_error",
            }

    def _optimize_image_for_analysis(self, image_path: str) -> str:
        """ì´ë¯¸ì§€ ìµœì í™” ì „ì²˜ë¦¬ - í™˜ê²½ë³„ í¬ê¸° ì¡°ì •"""
        try:
            with Image.open(image_path) as img:
                # í™˜ê²½ë³„ ìµœëŒ€ í¬ê¸° ì œí•œ
                max_size = self.max_image_size

                if max(img.size) > max_size:
                    # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í¬ê¸° ì¡°ì •
                    img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)

                    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                    import tempfile

                    with tempfile.NamedTemporaryFile(
                        delete=False, suffix=".jpg"
                    ) as tmp:
                        img.save(tmp.name, "JPEG", quality=85, optimize=True)
                        logger.info(
                            f"ğŸ“ ì´ë¯¸ì§€ ìµœì í™”: {image_path} -> {tmp.name} (max: {max_size})"
                        )
                        return tmp.name

            return image_path

        except Exception as e:
            logger.warning(f"âš ï¸ ì´ë¯¸ì§€ ìµœì í™” ì‹¤íŒ¨: {e}, ì›ë³¸ ì‚¬ìš©")
            return image_path

    def _create_fallback_detection(self, image_path: str) -> List[Dict]:
        """í´ë°± ê°ì§€ ê²°ê³¼ ìƒì„±"""
        with Image.open(image_path) as img:
            w, h = img.size
            return [
                {
                    "bbox": [0, 0, w, h],
                    "confidence": 0.7,
                    "class_id": 0,
                    "area_id": "full_image_fallback",
                }
            ]

    def _get_optimization_summary(self) -> Dict[str, Any]:
        """ì ìš©ëœ ì„¤ì • ìš”ì•½ (ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ê³ ì •í™•ë„ ì„¤ì •)"""
        return {
            "environment": self.config["environment"],
            "device": self.device,
            "max_image_size": self.max_image_size,  # ëª¨ë“  í™˜ê²½ì—ì„œ 2048
            "models_loaded": {
                "yolo": self.shared_models.get("yolo") is not None,
                "clip": self.shared_models.get("clip") is not None,
                "openai": self.shared_models.get("openai") is not None,
            },
            "high_accuracy_mode": True,  # ëª¨ë“  í™˜ê²½ì—ì„œ ê³ ì •í™•ë„
            "tta_enabled": True,  # ëª¨ë“  í™˜ê²½ì—ì„œ TTA í™œì„±í™”
            "batch_size": BATCH_SIZE,  # ëª¨ë“  í™˜ê²½ì—ì„œ 4
        }

    def _create_structured_analysis_data(
        self, detections: list, classifications: dict, area: float, user_message: str
    ) -> Dict[str, Any]:
        """êµ¬ì¡°í™”ëœ ë¶„ì„ ë°ì´í„° ìƒì„±"""
        from app.criteria_loader import get_criteria_manager

        criteria_manager = get_criteria_manager()
        damage_areas = []

        for i, detection in enumerate(detections):
            damage_type = detection.get("class", "unknown")
            confidence = detection.get("confidence", 0.0)

            # CLIP ë¶„ë¥˜ ê²°ê³¼ ë°˜ì˜
            if damage_type in classifications:
                classification = classifications[damage_type]
                damage_type_kr = classification.get("damage_type_kr", damage_type)
            else:
                damage_type_kr = self._get_korean_damage_type(damage_type)

            # ê¸°ì¤€ ë°ì´í„°ì—ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ
            criteria = criteria_manager.get_damage_assessment_criteria(damage_type)

            # ì‹¬ê°ë„ ê³„ì‚°
            severity_level = min(5, max(1, int(confidence * 5) + 1))
            severity_desc = (
                list(criteria.get("severity_levels", {}).values())[severity_level - 1]
                if criteria.get("severity_levels")
                else "ë³´í†µ ì†ìƒ"
            )

            # êµ¬ì¡°í™”ëœ í”¼í•´ ì˜ì—­ ë°ì´í„°
            damage_area = {
                "name": f"í”¼í•´ì˜ì—­ {i+1}",
                "damage_type": damage_type,
                "damage_type_kr": damage_type_kr,
                "confidence": confidence,
                "severity_level": severity_level,
                "description": f"{damage_type_kr} - {severity_desc} (ì‹ ë¢°ë„: {confidence:.2f})",
                "basis": self._get_recovery_basis(damage_type, criteria),
                "process": self._get_process_name(damage_type, criteria),
                "materials": self._get_material_list(damage_type, criteria),
                "coordinates": detection.get("bbox", [0, 0, 0, 0]),
            }

            damage_areas.append(damage_area)

        return {
            "basic_info": {
                "analysis_date": datetime.now().strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„"),
                "analysis_area": area,
                "user_message": user_message,
                "total_damages": len(
                    [d for d in damage_areas if d["damage_type"] != "normal building"]
                ),
                "total_areas": len(damage_areas),
            },
            "damage_areas": damage_areas,
            "summary": {
                "total_detections": len(detections),
                "damage_count": len(
                    [d for d in damage_areas if d["damage_type"] != "normal building"]
                ),
                "normal_count": len(
                    [d for d in damage_areas if d["damage_type"] == "normal building"]
                ),
            },
        }

    def _get_korean_damage_type(self, damage_type: str) -> str:
        """í”¼í•´ ìœ í˜• í•œêµ­ì–´ ë³€í™˜"""
        return DAMAGE_TYPE_KR_MAP.get(damage_type, damage_type)

    def _get_recovery_basis(self, damage_type: str, criteria: Dict) -> str:
        """ë³µêµ¬ ê·¼ê±° ìƒì„± (í‘œì¤€ì‹œë°©ì„œ ê¸°ë°˜)"""
        basis_templates = {
            "crack damage": "ã€Œê±´ì¶•ê³µì‚¬ í‘œì¤€ì‹œë°©ì„œã€ ì œ6ì¥ ì½˜í¬ë¦¬íŠ¸ê³µì‚¬ 6.5.3 ê· ì—´ë³´ìˆ˜ì— ë”°ë¼ ê· ì—´í­ 0.3mm ì´ìƒ ì‹œ ì—í­ì‹œ ìˆ˜ì§€ ì£¼ì…ê³µë²•ì„ ì ìš©í•˜ë©°, ã€ŒKCS 41 30 02 í˜„ì¥ì¹˜ê¸°ì½˜í¬ë¦¬íŠ¸ê³µì‚¬ã€ì˜ ê· ì—´ë³´ìˆ˜ ê¸°ì¤€ì„ ì¤€ìˆ˜í•©ë‹ˆë‹¤.",
            "water damage": "ã€Œê±´ì¶•ê³µì‚¬ í‘œì¤€ì‹œë°©ì„œã€ ì œ12ì¥ ë°©ìˆ˜ê³µì‚¬ ë° ã€ŒKCS 41 40 00 ë°©ìˆ˜ê³µì‚¬ã€ì— ë”°ë¼ ì¹¨ìˆ˜ í”¼í•´ ë¶€ìœ„ì˜ ê¸°ì¡´ ë°©ìˆ˜ì¸µ ì œê±° í›„ ë°”íƒ•ì²˜ë¦¬ ë° ì‹ ê·œ ë°©ìˆ˜ì¬ ì‹œê³µì„ ì‹¤ì‹œí•©ë‹ˆë‹¤.",
            "fire damage": "ã€Œê±´ì¶•ê³µì‚¬ í‘œì¤€ì‹œë°©ì„œã€ ì œ14ì¥ ë§ˆê°ê³µì‚¬ ë° ã€Œì¬ë‚œ ì•ˆì „ ê´€ë¦¬ ì§€ì¹¨ã€ì— ë”°ë¼ í™”ì¬ ì†ìƒ ë¶€ìœ„ì˜ êµ¬ì¡° ì•ˆì „ì„± ê²€í†  í›„ ì†ìƒ ì •ë„ì— ë”°ë¥¸ ë‹¨ê³„ì  ë³µêµ¬ë¥¼ ì‹¤ì‹œí•©ë‹ˆë‹¤.",
            "roof damage": "ã€Œê±´ì¶•ê³µì‚¬ í‘œì¤€ì‹œë°©ì„œã€ ì œ11ì¥ ì§€ë¶•ê³µì‚¬ ë° ã€ŒKCS 41 50 00 ì§€ë¶•ê³µì‚¬ã€ì— ë”°ë¼ ì§€ë¶•ì¬ êµì²´ ë° ë°©ìˆ˜ì¸µ ë³´ê°•ì„ ì‹¤ì‹œí•˜ë©°, êµ¬ì¡°ì²´ ì ê²€ì„ ì„ í–‰í•©ë‹ˆë‹¤.",
            "window damage": "ã€Œê±´ì¶•ê³µì‚¬ í‘œì¤€ì‹œë°©ì„œã€ ì œ9ì¥ ì°½í˜¸ê³µì‚¬ ë° ã€ŒKCS 41 60 00 ì°½í˜¸ê³µì‚¬ã€ì— ë”°ë¼ ì†ìƒëœ ì°½í˜¸ì˜ í•´ì²´ ë° ì‹ ê·œ ì°½í˜¸ ì„¤ì¹˜ë¥¼ ì‹¤ì‹œí•©ë‹ˆë‹¤.",
            "door damage": "ã€Œê±´ì¶•ê³µì‚¬ í‘œì¤€ì‹œë°©ì„œã€ ì œ9ì¥ ì°½í˜¸ê³µì‚¬ ë° ã€ŒKCS 41 60 00 ì°½í˜¸ê³µì‚¬ã€ì— ë”°ë¼ ì†ìƒëœ ë¬¸ì§ ë° ë¬¸í‹€ì˜ ë³´ìˆ˜ ë˜ëŠ” êµì²´ë¥¼ ì‹¤ì‹œí•©ë‹ˆë‹¤.",
            "foundation damage": "ã€Œê±´ì¶•ê³µì‚¬ í‘œì¤€ì‹œë°©ì„œã€ ì œ5ì¥ ê¸°ì´ˆê³µì‚¬ ë° ã€ŒKCS 41 20 00 ê¸°ì´ˆê³µì‚¬ã€ì— ë”°ë¼ ê¸°ì´ˆ êµ¬ì¡°ì²´ì˜ ì•ˆì „ì„± ê²€í†  í›„ ì–¸ë”í”¼ë‹ ë˜ëŠ” ë³´ê°•ê³µë²•ì„ ì ìš©í•©ë‹ˆë‹¤.",
            "structural deformation": "ã€Œê±´ì¶•êµ¬ì¡°ê¸°ì¤€ã€ ë° ã€ŒKCS 41 30 00 ì½˜í¬ë¦¬íŠ¸ê³µì‚¬ã€ì— ë”°ë¼ êµ¬ì¡° ì•ˆì „ì„± ì •ë°€ì§„ë‹¨ í›„ êµ¬ì¡°ë³´ê°• ì„¤ê³„ì— ì˜í•œ ë³´ê°•ê³µì‚¬ë¥¼ ì‹¤ì‹œí•©ë‹ˆë‹¤.",
            "facade damage": "ã€Œê±´ì¶•ê³µì‚¬ í‘œì¤€ì‹œë°©ì„œã€ ì œ14ì¥ ë§ˆê°ê³µì‚¬ ë° ã€ŒKCS 41 70 00 ë§ˆê°ê³µì‚¬ã€ì— ë”°ë¼ ì™¸ë²½ ë§ˆê°ì¬ì˜ í•´ì²´ ë° ì‹ ê·œ ì‹œê³µì„ ì‹¤ì‹œí•©ë‹ˆë‹¤.",
        }

        return basis_templates.get(
            damage_type,
            f"ã€Œê±´ì¶•ê³µì‚¬ í‘œì¤€ì‹œë°©ì„œã€ ë° ê´€ë ¨ KCS ê¸°ì¤€ì— ë”°ë¼ {damage_type} ë³µêµ¬ê³µì‚¬ë¥¼ ì‹¤ì‹œí•©ë‹ˆë‹¤.",
        )

    def _get_process_name(self, damage_type: str, criteria: Dict) -> str:
        """ê³µì •ëª… ìƒì„±"""
        process_names = {
            "crack damage": "ê· ì—´ë³´ìˆ˜ê³µì‚¬ â†’ ì—í­ì‹œìˆ˜ì§€ ì£¼ì…ê³µë²• â†’ í‘œë©´ ë§ˆê°ê³µì‚¬",
            "water damage": "ê¸°ì¡´ ë°©ìˆ˜ì¸µ ì œê±° â†’ ë°”íƒ•ì²˜ë¦¬ â†’ ë°©ìˆ˜ì¬ ë„í¬ â†’ ë³´í˜¸ì¸µ ì‹œê³µ",
            "fire damage": "í™”ì¬ì†ìƒë¶€ í•´ì²´ â†’ êµ¬ì¡°ë³´ê°• â†’ ë§ˆê°ì¬ ì‹œê³µ â†’ ë„ì¥ê³µì‚¬",
            "roof damage": "ê¸°ì¡´ ì§€ë¶•ì¬ í•´ì²´ â†’ ë°©ìˆ˜ì¸µ ë³´ê°• â†’ ì§€ë¶•ì¬ ì„¤ì¹˜ â†’ ë§ˆê°ê³µì‚¬",
            "window damage": "ê¸°ì¡´ ì°½í˜¸ í•´ì²´ â†’ ê°œêµ¬ë¶€ ì •ë¦¬ â†’ ì‹ ê·œ ì°½í˜¸ ì„¤ì¹˜ â†’ ì‹¤ë§ê³µì‚¬",
            "door damage": "ê¸°ì¡´ ë¬¸ í•´ì²´ â†’ ë¬¸í‹€ ì ê²€ â†’ ì‹ ê·œ ë¬¸ ì„¤ì¹˜ â†’ ë§ˆê°ê³µì‚¬",
            "foundation damage": "ê¸°ì´ˆ êµ´ì°© â†’ êµ¬ì¡°ë³´ê°• â†’ ì–¸ë”í”¼ë‹ â†’ ë˜ë©”ìš°ê¸°",
            "structural deformation": "êµ¬ì¡°ì§„ë‹¨ â†’ ë³´ê°•ì„¤ê³„ â†’ êµ¬ì¡°ë³´ê°•ê³µì‚¬ â†’ ë§ˆê°ë³µêµ¬",
            "facade damage": "ê¸°ì¡´ ë§ˆê°ì¬ í•´ì²´ â†’ ë°”íƒ•ì²˜ë¦¬ â†’ ì‹ ê·œ ë§ˆê°ì¬ ì‹œê³µ â†’ ì‹¤ë§ê³µì‚¬",
        }

        return process_names.get(damage_type, f"{damage_type} ë³µêµ¬ê³µì‚¬")

    def _get_material_list(self, damage_type: str, criteria: Dict) -> list:
        """ë³µêµ¬ ì˜ˆìƒ ìì¬ ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
        materials_dict = {
            "crack damage": [
                {"name": "ì—í­ì‹œ ìˆ˜ì§€", "usage": "ê· ì—´ ì£¼ì…ìš©"},
                {"name": "í”„ë¼ì´ë¨¸", "usage": "ì ‘ì°©ë ¥ í–¥ìƒ"},
                {"name": "ì‹¤ë§ì¬", "usage": "í‘œë©´ ë§ˆê°"},
            ],
            "water damage": [
                {"name": "ìš°ë ˆíƒ„ ë°©ìˆ˜ì¬", "usage": "ë°©ìˆ˜ì¸µ í˜•ì„±"},
                {"name": "í”„ë¼ì´ë¨¸", "usage": "ë°”íƒ•ì²˜ë¦¬"},
                {"name": "ë³´í˜¸ëª°íƒˆ", "usage": "ë°©ìˆ˜ì¸µ ë³´í˜¸"},
            ],
            "fire damage": [
                {"name": "ë‚´í™” ë³´ë“œ", "usage": "ë‚´í™”ì„±ëŠ¥ í™•ë³´"},
                {"name": "êµ¬ì¡°ìš© ì ‘ì°©ì œ", "usage": "êµ¬ì¡° ë³´ê°•"},
                {"name": "ë‚´í™” ë„ë£Œ", "usage": "ë§ˆê° ë° ë³´í˜¸"},
            ],
            "roof damage": [
                {"name": "ê¸°ì™€ ë˜ëŠ” ìŠ¬ë ˆì´íŠ¸", "usage": "ì§€ë¶•ì¬"},
                {"name": "ë°©ìˆ˜ì‹œíŠ¸", "usage": "ë°©ìˆ˜ì¸µ"},
                {"name": "ë‹¨ì—´ì¬", "usage": "ë‹¨ì—´ì„±ëŠ¥"},
            ],
            "window damage": [
                {"name": "ì•Œë£¨ë¯¸ëŠ„ ì°½í˜¸", "usage": "ì°½í˜¸ êµì²´"},
                {"name": "ë³µì¸µìœ ë¦¬", "usage": "ë‹¨ì—´ì„±ëŠ¥"},
                {"name": "ì‹¤ë§ì¬", "usage": "ê¸°ë°€ì„± í™•ë³´"},
            ],
            "door damage": [
                {"name": "ëª©ì¬ ë˜ëŠ” ìŠ¤í‹¸ ë„ì–´", "usage": "ë¬¸ì§ êµì²´"},
                {"name": "ê²½ì²© ë° ì†ì¡ì´", "usage": "í•˜ë“œì›¨ì–´"},
                {"name": "ì‹¤ë§ì¬", "usage": "ê¸°ë°€ì„± í™•ë³´"},
            ],
            "foundation damage": [
                {"name": "êµ¬ì¡°ìš© ì½˜í¬ë¦¬íŠ¸", "usage": "ê¸°ì´ˆ ë³´ê°•"},
                {"name": "ì² ê·¼", "usage": "êµ¬ì¡° ë³´ê°•"},
                {"name": "ë°©ìˆ˜ì¬", "usage": "ì§€í•˜ ë°©ìˆ˜"},
            ],
            "structural deformation": [
                {"name": "êµ¬ì¡°ìš© ê°•ì¬", "usage": "êµ¬ì¡° ë³´ê°•"},
                {"name": "ê³ ê°•ë„ ë³¼íŠ¸", "usage": "ì ‘í•©ë¶€"},
                {"name": "ë¬´ìˆ˜ì¶• ëª°íƒˆ", "usage": "ì¶©ì „ì¬"},
            ],
            "facade damage": [
                {"name": "ì™¸ì¥ ë§ˆê°ì¬", "usage": "ì™¸ë²½ ë§ˆê°"},
                {"name": "ë‹¨ì—´ì¬", "usage": "ë‹¨ì—´ì„±ëŠ¥"},
                {"name": "ë§ˆê° ë„ë£Œ", "usage": "ìµœì¢… ë§ˆê°"},
            ],
        }

        return materials_dict.get(
            damage_type, [{"name": "í‘œì¤€ ê±´ì¶•ìì¬", "usage": "ë³µêµ¬ìš©"}]
        )

    def _generate_user_friendly_text(self, structured_data: Dict) -> str:
        """ì‚¬ìš©ì ì¹œí™”ì  í…ìŠ¤íŠ¸ ìƒì„± (í‘œì¤€ì‹œë°©ì„œ ê·¼ê±° í¬í•¨)"""
        basic_info = structured_data["basic_info"]
        damage_areas = structured_data["damage_areas"]

        sections = []

        # 1. í”¼í•´ í˜„í™©
        sections.append("í”¼í•´ í˜„í™©")
        sections.append(
            f"ì´ {basic_info['total_areas']}ê°œ ì˜ì—­ ì¤‘ {basic_info['total_damages']}ê°œ í”¼í•´ ì˜ì—­ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤."
        )

        for area in damage_areas:
            if area["damage_type"] != "normal building":
                sections.append(f"â€¢ {area['name']}: {area['description']}")

        # 2. ë³µêµ¬ ê·¼ê±°
        sections.append("\në³µêµ¬ ê·¼ê±°")
        for area in damage_areas:
            if area["damage_type"] != "normal building":
                sections.append(f"**{area['name']}**: {area['basis']}")

        # 3. ê³µì •ëª…
        sections.append("\në³µêµ¬ ê³µì •")
        for area in damage_areas:
            if area["damage_type"] != "normal building":
                sections.append(f"**{area['name']}**: {area['process']}")

        # 4. ë³µêµ¬ ì˜ˆìƒ ìì¬
        sections.append("\në³µêµ¬ ì˜ˆìƒ ìì¬")
        for area in damage_areas:
            if area["damage_type"] != "normal building":
                sections.append(f"**{area['name']}**:")
                for material in area["materials"]:
                    sections.append(f"  - {material['name']}: {material['usage']}")

        return "\n".join(sections)


class OptimizedYOLODetector:
    """ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ê³ ì„±ëŠ¥ YOLOv8 ê±´ë¬¼ í”¼í•´ ê°ì§€"""

    def __init__(self, shared_model=None):
        """ê³µìœ  ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©"""
        self.model = shared_model
        self.device = DEVICE

        if self.model:
            logger.info("âœ… YOLO ì»¤ìŠ¤í…€ ëª¨ë¸ ê³µìœ  ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©")
        else:
            logger.error("âŒ YOLO ì»¤ìŠ¤í…€ ëª¨ë¸ ì—†ìŒ - ì‹œìŠ¤í…œ ì¤‘ë‹¨")
            raise ValueError("ì»¤ìŠ¤í…€ YOLO ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤")

    def detect_damage_areas(self, image_path: str, use_tta: bool = True) -> List[Dict]:
        """ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ê³ ì„±ëŠ¥ í”¼í•´ ì˜ì—­ ê°ì§€"""
        if not self.model:
            logger.error("âŒ YOLO ëª¨ë¸ ì—†ìŒ")
            raise ValueError("YOLO ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ê³ ì„±ëŠ¥ ì„¤ì • ì‚¬ìš©
            return self._detect_with_high_accuracy(image_path, use_tta)

        except Exception as e:
            logger.error(f"âŒ YOLO ê°ì§€ ì˜¤ë¥˜: {e}")
            # í´ë°± ëŒ€ì‹  ì—ëŸ¬ ë°œìƒ (ì»¤ìŠ¤í…€ ëª¨ë¸ ê°•ì œ)
            raise e

    def _detect_with_high_accuracy(
        self, image_path: str, use_tta: bool = True
    ) -> List[Dict]:
        """ê³ ì„±ëŠ¥ ê°ì§€ - ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ì„¤ì •"""
        # ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ê³ ì„±ëŠ¥ ì„¤ì •
        conf_threshold = 0.3  # ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë” ë§ì€ ê°ì§€
        max_det = 50  # ë” ë§ì€ ê°ì§€ í—ˆìš©

        if use_tta:
            # TTA ì ìš© - ëª¨ë“  í™˜ê²½ì—ì„œ í™œì„±í™”
            results_list = []

            # ì›ë³¸ ì´ë¯¸ì§€
            results_list.append(
                self.model(
                    image_path,
                    conf=conf_threshold,
                    max_det=max_det,
                    device=self.device,
                    verbose=False,
                )
            )

            # ì¢Œìš° ë°˜ì „
            results_list.append(
                self.model(
                    image_path,
                    conf=conf_threshold,
                    max_det=max_det,
                    device=self.device,
                    verbose=False,
                    augment=True,
                )
            )

            # ìµœê³  ì‹ ë¢°ë„ ê²°ê³¼ ì„ íƒ
            best_results = results_list[0]
            for results in results_list[1:]:
                for r in results:
                    if r.boxes is not None and len(r.boxes) > len(
                        best_results[0].boxes or []
                    ):
                        best_results = results
                        break

            results = best_results
        else:
            results = self.model(
                image_path,
                conf=conf_threshold,
                max_det=max_det,
                device=self.device,
                verbose=False,
            )

        detections = []
        for r in results:
            boxes = r.boxes
            if boxes is not None:
                for i, box in enumerate(boxes):
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = float(box.conf[0].cpu().numpy())
                    class_id = int(box.cls[0].cpu().numpy())

                    detections.append(
                        {
                            "bbox": [int(x1), int(y1), int(x2), int(y2)],
                            "confidence": confidence,
                            "class_id": class_id,
                            "area_id": f"custom_yolo_area_{i}",
                        }
                    )

        if not detections:
            # ìµœì†Œí•œì˜ í´ë°± (ì „ì²´ ì´ë¯¸ì§€)
            logger.warning("âš ï¸ YOLOì—ì„œ ê°ì§€ëœ í”¼í•´ ì—†ìŒ, ì „ì²´ ì´ë¯¸ì§€ ë¶„ì„")
            return self._minimal_fallback_detection(image_path)

        return detections

    def _minimal_fallback_detection(self, image_path: str) -> List[Dict]:
        """ìµœì†Œí•œì˜ í´ë°± ê°ì§€ (ì „ì²´ ì´ë¯¸ì§€ë§Œ)"""
        try:
            with Image.open(image_path) as img:
                w, h = img.size
                return [
                    {
                        "bbox": [0, 0, w, h],
                        "confidence": 0.6,
                        "class_id": 0,
                        "area_id": "full_image_analysis",
                    }
                ]
        except:
            return [
                {
                    "bbox": [0, 0, 800, 600],
                    "confidence": 0.5,
                    "class_id": 0,
                    "area_id": "default_analysis",
                }
            ]


class OptimizedCLIPClassifier:
    """ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ê³ ì„±ëŠ¥ CLIP ê¸°ë°˜ í”¼í•´ ìœ í˜• ë¶„ë¥˜"""

    def __init__(self, shared_model_data=None):
        """ê³µìœ  ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©"""
        self.device = DEVICE

        if shared_model_data and len(shared_model_data) == 2:
            self.model, self.preprocess = shared_model_data
            logger.info("âœ… CLIP ëª¨ë¸ ê³µìœ  ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©")
        else:
            self.model = None
            self.preprocess = None
            logger.warning("âš ï¸ CLIP ëª¨ë¸ ì—†ìŒ, fallback ëª¨ë“œ")

    def classify_damage_type(self, image_crop: Image.Image) -> Dict[str, float]:
        """ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ê³ ì„±ëŠ¥ í”¼í•´ ìœ í˜• ë¶„ë¥˜"""
        if not self.model:
            return self._fallback_classification()

        try:
            # ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ê³ í•´ìƒë„ ì²˜ë¦¬
            image_crop = image_crop.resize((224, 224), Image.Resampling.LANCZOS)

            image_input = self.preprocess(image_crop).unsqueeze(0).to(self.device)

            # ëª¨ë“  í™˜ê²½ì—ì„œ ì „ì²´ í”¼í•´ ìœ í˜• ë¶„ë¥˜ (ì œí•œ ì—†ìŒ)
            damage_types = DAMAGE_TYPES  # ì „ì²´ í”¼í•´ ìœ í˜• ì‚¬ìš©
            text_inputs = torch.cat(
                [
                    self._tokenize_with_fallback(f"a photo of {damage_type}")
                    for damage_type in damage_types
                ]
            ).to(self.device)

            # ì¶”ë¡  ì‹¤í–‰
            with torch.no_grad():
                logits_per_image, _ = self.model(image_input, text_inputs)
                probs = logits_per_image.softmax(dim=-1).cpu().numpy()[0]

            # ê²°ê³¼ ë§¤í•‘
            result = {}
            for i, damage_type in enumerate(damage_types):
                result[damage_type] = float(probs[i])

            return result

        except Exception as e:
            logger.error(f"âŒ CLIP ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return self._fallback_classification()

    def _tokenize_with_fallback(self, text: str):
        """ì•ˆì „í•œ í† í°í™”"""
        try:
            import clip

            return clip.tokenize(text)
        except:
            # Fallback - ë”ë¯¸ í† í°
            return torch.zeros(1, 77, dtype=torch.long)

    def _fallback_classification(self) -> Dict[str, float]:
        """ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¶„ë¥˜"""
        return {damage_type: 0.1 for damage_type in DAMAGE_TYPES}

    def classify_damage_areas_batch(
        self, image_path: str, detections: List[Dict]
    ) -> List[Dict]:
        """ê³ ì •í™•ë„ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì—¬ëŸ¬ ì˜ì—­ ë¶„ë¥˜"""
        results = []

        try:
            with Image.open(image_path) as img:
                # ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ë°°ì¹˜ í¬ê¸° ì‚¬ìš©
                batch_size = min(BATCH_SIZE, len(detections))  # ì„¤ì •ëœ ë°°ì¹˜ í¬ê¸° ì‚¬ìš©

                for i in range(0, len(detections), batch_size):
                    batch_detections = detections[i : i + batch_size]
                    batch_results = []

                    for detection in batch_detections:
                        bbox = detection["bbox"]
                        crop = img.crop((bbox[0], bbox[1], bbox[2], bbox[3]))
                        result = self.classify_damage_type(crop)
                        batch_results.append(result)

                    results.extend(batch_results)

            return results

        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return [self._fallback_classification() for _ in detections]


class OptimizedGPTGenerator:
    """ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ê³ ì„±ëŠ¥ GPT ë³´ê³ ì„œ ìƒì„±ê¸°"""

    def __init__(self, shared_client=None):
        """ê³µìœ  OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©"""
        self.client = shared_client

        if self.client:
            logger.info("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ê³µìœ  ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©")
        else:
            logger.warning("âš ï¸ OpenAI í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ, fallback ëª¨ë“œ")

        # LangChain ì„¤ì • (ì„ íƒì )
        self.llm = None
        self.prompt = None

        if LANGCHAIN_AVAILABLE and self.client:
            try:
                api_key = os.getenv("OPENAI_API_KEY")
                if api_key:
                    self.llm = LangChainOpenAI(
                        temperature=0.3,  # ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ì˜¨ë„
                        openai_api_key=api_key,
                        max_tokens=2000,  # ëª¨ë“  í™˜ê²½ì—ì„œ ë†’ì€ í† í° ì œí•œ
                    )

                    self.prompt_template = """
ë‹¹ì‹ ì€ ê±´ë¬¼ í”¼í•´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ê±´ë¬¼ í”¼í•´ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë¶„ì„ ë°ì´í„°: {analysis_data}

ë‹¤ìŒ êµ¬ì¡°ë¡œ ìƒì„¸í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. í”¼í•´ í˜„í™© ìš”ì•½
2. ì£¼ìš” í”¼í•´ ì˜ì—­ ë¶„ì„ (ê° ì˜ì—­ë³„ ìƒì„¸ ì„¤ëª…)
3. ë³µêµ¬ ê¶Œê³ ì‚¬í•­ (ìš°ì„ ìˆœìœ„ í¬í•¨)
4. ì•ˆì „ì„± í‰ê°€

ë³´ê³ ì„œëŠ” ì „ë¬¸ì ì´ë©´ì„œë„ ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

                    self.prompt = PromptTemplate(
                        input_variables=["analysis_data"],
                        template=self.prompt_template,
                    )

                    logger.info("âœ… LangChain GPT ì„¤ì • ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ LangChain ì„¤ì • ì‹¤íŒ¨: {e}")

    def generate_report(
        self, analysis_results: Dict, criteria_data: Dict = None
    ) -> str:
        """ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ê³ ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±"""
        try:
            if self.llm and self.prompt:
                # LangChain ì‚¬ìš© (ìµœì‹  íŒ¨í„´)
                formatted_prompt = self.prompt.format(
                    analysis_data=str(analysis_results)[:3000]  # ë” ë§ì€ í† í° í—ˆìš©
                )
                response = self.llm.invoke(formatted_prompt)
                return response

            elif self.client:
                # ì§ì ‘ OpenAI API ì‚¬ìš© - ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ê³ ì„±ëŠ¥ ì„¤ì •
                model = "gpt-4o"  # ëª¨ë“  í™˜ê²½ì—ì„œ ìµœê³  í’ˆì§ˆ ëª¨ë¸
                max_tokens = 2000  # ëª¨ë“  í™˜ê²½ì—ì„œ ë†’ì€ í† í° ì œí•œ

                messages = [
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ê±´ë¬¼ í”¼í•´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìƒì„¸í•˜ê³  ì •í™•í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.",
                    },
                    {
                        "role": "user",
                        "content": f"""
ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ê±´ë¬¼ í”¼í•´ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

{str(analysis_results)[:3000]}

êµ¬ì¡°:
1. í”¼í•´ í˜„í™© ìš”ì•½
2. ì£¼ìš” í”¼í•´ ì˜ì—­ ìƒì„¸ ë¶„ì„
3. ë³µêµ¬ ê¶Œê³ ì‚¬í•­ (ìš°ì„ ìˆœìœ„ í¬í•¨)
4. ì•ˆì „ì„± í‰ê°€

ìƒì„¸í•˜ê³  ì „ë¬¸ì ì¸ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
""",
                    },
                ]

                response = self.client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=0.3,
                    max_tokens=max_tokens,
                )

                return response.choices[0].message.content

            else:
                return self._generate_fallback_report(analysis_results)

        except Exception as e:
            logger.error(f"âŒ ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._generate_fallback_report(analysis_results)

    def _generate_fallback_report(self, analysis_results: Dict) -> str:
        """GPT ì‹¤íŒ¨ ì‹œ êµ¬ì¡°í™”ëœ ê¸°ë³¸ ë³´ê³ ì„œ"""
        damage_count = len(analysis_results.get("damage_areas", []))

        return f"""
# ê±´ë¬¼ í”¼í•´ ë¶„ì„ ë³´ê³ ì„œ

## ë¶„ì„ ê°œìš”
- ë¶„ì„ ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}
- ê°ì§€ëœ í”¼í•´ ì˜ì—­: {damage_count}ê°œ
- ë¶„ì„ í™˜ê²½: {APP_CONFIG.get('environment', 'unknown')}

## ì£¼ìš” ê²°ê³¼
{analysis_results.get('analysis_text', 'ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.')}

## ê¶Œê³ ì‚¬í•­
ê°ì§€ëœ í”¼í•´ì— ëŒ€í•´ ì „ë¬¸ê°€ì˜ ìƒì„¸ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë³´ìˆ˜ ê³„íšì„ ìˆ˜ë¦½í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

---
*ë³¸ ë³´ê³ ì„œëŠ” AI ë¶„ì„ ê²°ê³¼ì´ë©°, ì •í™•í•œ ì§„ë‹¨ì„ ìœ„í•´ì„œëŠ” ì „ë¬¸ê°€ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.*
"""


def analyze_damage_with_ai(
    image_path: str,
    area: float,
    user_message: str,
) -> str:

    start_time = time.time()

    try:
        # Show single loading message
        with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):

            # 1ë‹¨ê³„: YOLOv8ë¡œ í”¼í•´ ì˜ì—­ ê°ì§€
            logger.info("1ë‹¨ê³„: YOLOv8 í”¼í•´ ì˜ì—­ ê°ì§€ ì‹œì‘")
            yolo_detector = OptimizedYOLODetector()
            damage_areas = yolo_detector.detect_damage_areas(image_path)

            # 2ë‹¨ê³„: CLIPìœ¼ë¡œ ê° ì˜ì—­ì˜ í”¼í•´ ìœ í˜• ë¶„ë¥˜
            logger.info("2ë‹¨ê³„: CLIP í”¼í•´ ìœ í˜• ë¶„ë¥˜ ì‹œì‘")
            clip_classifier = OptimizedCLIPClassifier()

            image = Image.open(image_path)
            classified_damages = []

            for area_info in damage_areas:
                bbox = area_info["bbox"]

                # ì´ë¯¸ì§€ í¬ë¡­
                crop = image.crop((bbox[0], bbox[1], bbox[2], bbox[3]))

                # CLIP ë¶„ë¥˜
                classification = clip_classifier.classify_damage_type(crop)

                # ìµœê³  í™•ë¥  í”¼í•´ ìœ í˜• ì„ íƒ
                best_damage_type = max(classification, key=classification.get)
                confidence = classification[best_damage_type]

                classified_damages.append(
                    {
                        "area_id": area_info["area_id"],
                        "bbox": bbox,
                        "damage_type": best_damage_type,
                        "damage_type_kr": DAMAGE_TYPE_KR_MAP.get(
                            best_damage_type, best_damage_type
                        ),
                        "confidence": confidence,
                        "yolo_confidence": area_info["confidence"],
                    }
                )

            # 3ë‹¨ê³„: ìƒˆë¡œìš´ CriteriaDataManagerë¡œ ê¸°ì¤€ ë°ì´í„° ë§¤í•‘
            logger.info("3ë‹¨ê³„: ê¸°ì¤€ ë°ì´í„° ë§¤í•‘ ì‹œì‘")
            criteria_manager = get_criteria_manager()

            repair_specifications = []
            for damage in classified_damages:
                if damage["damage_type"] != "normal building":
                    # ìƒˆë¡œìš´ ë§¤ë‹ˆì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„¸í•œ í‰ê°€ ê¸°ì¤€ ì¡°íšŒ
                    damage_criteria = criteria_manager.get_damage_assessment_criteria(
                        damage["damage_type"]
                    )
                    damage_criteria["damage_info"] = damage
                    repair_specifications.append(damage_criteria)

            # 4ë‹¨ê³„: ë¶„ì„ ê²°ê³¼ êµ¬ì„±
            analysis_results = {
                "image_path": image_path,
                "area_sqm": area,
                "user_message": user_message,
                "damage_areas": classified_damages,
                "repair_specifications": repair_specifications,
                "total_damages": len(
                    [
                        d
                        for d in classified_damages
                        if d["damage_type"] != "normal building"
                    ]
                ),
                "analysis_time": time.time() - start_time,
            }

            # 5ë‹¨ê³„: ìƒˆë¡œìš´ CriteriaDataManagerë¡œ ì¢…í•© ë³´ê³ ì„œ ìƒì„±
            logger.info("5ë‹¨ê³„: ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì‹œì‘")
            final_report = criteria_manager.generate_comprehensive_report(
                analysis_results
            )

            # ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥
            try:
                annotated_image = create_damage_visualization(
                    image_path, classified_damages
                )

                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (UIì—ì„œ í‘œì‹œìš©)
                import tempfile

                with tempfile.NamedTemporaryFile(
                    delete=False, suffix=".png"
                ) as tmp_file:
                    annotated_image.save(tmp_file.name)
                    analysis_results["annotated_image_path"] = tmp_file.name

                logger.info("í”¼í•´ ê°ì§€ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")

            analysis_time = time.time() - start_time
            logger.info(f"ìƒˆë¡œìš´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {analysis_time:.2f}ì´ˆ")

            return final_report

    except Exception as e:
        logger.error(f"ë¶„ì„ ì˜¤ë¥˜: {e}")
        return f"""
ê±´ë¬¼ í”¼í•´ ë¶„ì„ ì˜¤ë¥˜

ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}

ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.
"""


def create_damage_visualization(
    image_path: str, damage_results: List[Dict]
) -> Image.Image:
    """í”¼í•´ ê°ì§€ ê²°ê³¼ë¥¼ ì‹œê°í™”í•œ ì´ë¯¸ì§€ ìƒì„±"""
    try:
        # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(image_path)
        draw = ImageDraw.Draw(image)

        # ìƒ‰ìƒ ë§¤í•‘ (í”¼í•´ ìœ í˜•ë³„)
        color_map = {
            "crack damage": "#FF6B6B",  # ë¹¨ê°„ìƒ‰
            "water damage": "#4ECDC4",  # ì²­ë¡ìƒ‰
            "fire damage": "#FF8E53",  # ì£¼í™©ìƒ‰
            "roof damage": "#95E1D3",  # ì—°ë‘ìƒ‰
            "window damage": "#A8E6CF",  # ë¯¼íŠ¸ìƒ‰
            "door damage": "#FFEAA7",  # ë…¸ë€ìƒ‰
            "foundation damage": "#DDA0DD",  # ìì£¼ìƒ‰
            "structural deformation": "#FF7675",  # ë¶„í™ìƒ‰
            "facade damage": "#74B9FF",  # íŒŒë€ìƒ‰
            "normal building": "#00B894",  # ì´ˆë¡ìƒ‰
        }

        # ê° ê°ì§€ ì˜ì—­ì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for damage in damage_results:
            if "bbox" in damage:
                bbox = damage["bbox"]
                damage_type = damage.get("damage_type", "normal building")
                confidence = damage.get("confidence", 0.0)

                # ë°”ìš´ë”© ë°•ìŠ¤ ìƒ‰ìƒ
                color = color_map.get(damage_type, "#GRAY")

                # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                draw.rectangle(bbox, outline=color, width=3)

                # ë¼ë²¨ í…ìŠ¤íŠ¸
                damage_kr = damage.get("damage_type_kr", damage_type)
                label = f"{damage_kr} ({confidence:.2f})"

                # ë¼ë²¨ ë°°ê²½
                text_bbox = draw.textbbox((bbox[0], bbox[1] - 25), label)
                draw.rectangle(text_bbox, fill=color)

                # ë¼ë²¨ í…ìŠ¤íŠ¸
                draw.text((bbox[0], bbox[1] - 25), label, fill="white")

        return image

    except Exception as e:
        logger.error(f"ì‹œê°í™” ìƒì„± ì˜¤ë¥˜: {e}")
        # ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
        return Image.open(image_path)
