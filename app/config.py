"""
ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ë° ì´ˆê¸°í™” - í™˜ê²½ë³„ ìë™ ìµœì í™”
"""

import streamlit as st
import os
import logging
import platform
import sys
from pathlib import Path


# í™˜ê²½ ê°ì§€
def detect_environment():
    """ì‹¤í–‰ í™˜ê²½ ìë™ ê°ì§€"""
    # Streamlit Cloud ê°ì§€
    if os.getenv("STREAMLIT_CLOUD") or "streamlit" in str(sys.path):
        return "streamlit_cloud"

    # Heroku ê°ì§€
    if os.getenv("DYNO"):
        return "heroku"

    # Railway ê°ì§€
    if os.getenv("RAILWAY_STATIC_URL"):
        return "railway"

    # Docker ê°ì§€
    if os.path.exists("/.dockerenv"):
        return "docker"

    # ë¡œì»¬ ê°œë°œ í™˜ê²½
    return "local"


# í™˜ê²½ë³„ ìë™ ì„¤ì •
ENVIRONMENT = detect_environment()
IS_DEPLOYMENT = ENVIRONMENT != "local"

# í™˜ê²½ë³„ ìµœì í™” ì„¤ì •
# ë°°í¬ í™˜ê²½ë„ ë¡œì»¬ê³¼ ë™ì¼í•œ ì„¤ì • ì‚¬ìš© (ëŠë ¤ë„ ì •í™•ë„ ìš°ì„ )
LOG_LEVEL = logging.INFO
DEVICE = "cuda" if os.getenv("CUDA_VISIBLE_DEVICES") != "none" else "cpu"
BATCH_SIZE = 4
MAX_IMAGE_SIZE = 2048

# Setup logging
logging.basicConfig(level=LOG_LEVEL)
logger = logging.getLogger(__name__)

# Reduce verbosity of external libraries
logging.getLogger("transformers").setLevel(logging.WARNING)
logging.getLogger("torch").setLevel(logging.WARNING)
logging.getLogger("PIL").setLevel(logging.WARNING)

logger.info(f"ğŸŒ í™˜ê²½ ê°ì§€: {ENVIRONMENT} ({'ë°°í¬' if IS_DEPLOYMENT else 'ë¡œì»¬'})")
logger.info(f"âš™ï¸ ë””ë°”ì´ìŠ¤: {DEVICE}, ë°°ì¹˜í¬ê¸°: {BATCH_SIZE}")

# Global variables for module availability
MODULES_LOADED = False
DAMAGE_CATEGORIES = {}
CACHE_DIR = Path("./cache")
MODEL_CACHE_DIR = CACHE_DIR / "models"

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ URL ì„¤ì • (ë°°í¬ í™˜ê²½ìš©)
MODEL_URLS = {
    "yolo_custom": "https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt",
    "clip_base": "ViT-B/32",  # CLIP ê¸°ë³¸ ëª¨ë¸
}

# ì™¸ë¶€ ëª¨ë¸ ì €ì¥ì†Œ URL (ë°°í¬ í™˜ê²½ì—ì„œ ì»¤ìŠ¤í…€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œìš©)
# ì‹¤ì œ ì‚¬ìš© ì‹œ ì•„ë˜ URLë“¤ì„ ì‹¤ì œ ëª¨ë¸ URLë¡œ ë³€ê²½í•˜ì„¸ìš”
EXTERNAL_MODEL_URLS = {
    # Google Drive ê³µìœ  ë§í¬ (ë‹¤ìš´ë¡œë“œ ì§ë§í¬ë¡œ ë³€í™˜ í•„ìš”)
    "custom_yolo_gdrive": "https://drive.google.com/uc?id=YOUR_GOOGLE_DRIVE_FILE_ID",
    # GitHub Releases (ê¶Œì¥ë°©ë²•)
    "custom_yolo_github": "https://github.com/YOUR_USERNAME/YOUR_REPO/releases/download/v1.0/custom_yolo_damage.pt",
    # Hugging Face Hub
    "custom_yolo_hf": "https://huggingface.co/YOUR_USERNAME/building-damage-yolo/resolve/main/custom_yolo_damage.pt",
    # CLIP íŒŒì¸íŠœë‹ ëª¨ë¸ (ì¶”í›„ ì‚¬ìš©)
    "clip_finetuned_hf": "https://huggingface.co/YOUR_USERNAME/building-damage-clip/resolve/main/clip_finetuned.pt",
}


def download_model_from_url(url: str, target_path: Path) -> bool:
    """ì™¸ë¶€ URLì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    try:
        import requests

        logger.info(f"ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {url}")

        # ë””ë ‰í† ë¦¬ ìƒì„±
        target_path.parent.mkdir(parents=True, exist_ok=True)

        # í—¤ë” ì„¤ì • (ì¼ë¶€ ì„œë¹„ìŠ¤ì—ì„œ User-Agent í•„ìš”)
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }

        response = requests.get(url, stream=True, headers=headers, timeout=300)
        response.raise_for_status()

        # íŒŒì¼ í¬ê¸° í™•ì¸
        total_size = int(response.headers.get("content-length", 0))

        with open(target_path, "wb") as f:
            downloaded = 0
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)

                    # ì§„í–‰ë¥  ë¡œê¹… (í° íŒŒì¼ì˜ ê²½ìš°)
                    if total_size > 0 and downloaded % (1024 * 1024) == 0:  # 1MBë§ˆë‹¤
                        progress = (downloaded / total_size) * 100
                        logger.info(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì§„í–‰ë¥ : {progress:.1f}%")

        # íŒŒì¼ í¬ê¸° ê²€ì¦
        if target_path.stat().st_size < 1024:  # 1KB ë¯¸ë§Œì´ë©´ ì˜¤ë¥˜
            logger.error("âŒ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤")
            target_path.unlink()
            return False

        logger.info(
            f"âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {target_path} ({target_path.stat().st_size / 1024 / 1024:.1f}MB)"
        )
        return True

    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        if target_path.exists():
            target_path.unlink()  # ì‹¤íŒ¨í•œ íŒŒì¼ ì‚­ì œ
        return False


@st.cache_resource
def initialize_optimized_models():
    """ëª¨ë“  í™˜ê²½ì—ì„œ ê³ ì •í™•ë„ ëª¨ë¸ ì´ˆê¸°í™” - ë°°í¬í™˜ê²½ ì»¤ìŠ¤í…€ ëª¨ë¸ ì§€ì›"""
    logger.info("ğŸš€ ê³ ì •í™•ë„ ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘")

    models = {}

    try:
        # YOLOv8 ëª¨ë¸ ë¡œë”© (ë°°í¬í™˜ê²½ ì»¤ìŠ¤í…€ ëª¨ë¸ ì§€ì›)
        from ultralytics import YOLO

        # 1ìˆœìœ„: ë¡œì»¬ ì»¤ìŠ¤í…€ ëª¨ë¸
        local_custom_path = Path("train/models/custom_yolo_damage.pt")

        # 2ìˆœìœ„: ë°°í¬í™˜ê²½ ìºì‹œëœ ì»¤ìŠ¤í…€ ëª¨ë¸
        cached_custom_path = MODEL_CACHE_DIR / "custom_yolo_damage.pt"

        if local_custom_path.exists():
            # ë¡œì»¬ ì»¤ìŠ¤í…€ ëª¨ë¸ ì‚¬ìš©
            models["yolo"] = YOLO(str(local_custom_path))
            logger.info("âœ… YOLOv8 ë¡œì»¬ ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        elif cached_custom_path.exists():
            # ìºì‹œëœ ì»¤ìŠ¤í…€ ëª¨ë¸ ì‚¬ìš©
            models["yolo"] = YOLO(str(cached_custom_path))
            logger.info("âœ… YOLOv8 ìºì‹œëœ ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        elif IS_DEPLOYMENT:
            # ë°°í¬í™˜ê²½ì—ì„œ ì»¤ìŠ¤í…€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œë„
            logger.info("ğŸŒ ë°°í¬í™˜ê²½ ê°ì§€ - ì»¤ìŠ¤í…€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œë„")

            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ëª¨ë¸ URL í™•ì¸
            custom_model_url = os.getenv("CUSTOM_YOLO_URL")

            if custom_model_url:
                logger.info(f"ğŸ“¥ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì»¤ìŠ¤í…€ ëª¨ë¸ URL ë°œê²¬: {custom_model_url}")
                if download_model_from_url(custom_model_url, cached_custom_path):
                    models["yolo"] = YOLO(str(cached_custom_path))
                    logger.info("âœ… YOLOv8 ë‹¤ìš´ë¡œë“œëœ ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                else:
                    logger.warning("âš ï¸ ì»¤ìŠ¤í…€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")
                    models["yolo"] = YOLO("yolov8n.pt")
                    logger.info("âœ… YOLOv8 ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.info("ğŸ“ CUSTOM_YOLO_URL í™˜ê²½ë³€ìˆ˜ ì—†ìŒ, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")
                models["yolo"] = YOLO("yolov8n.pt")
                logger.info("âœ… YOLOv8 ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        else:
            # ë¡œì»¬í™˜ê²½ì—ì„œ ì»¤ìŠ¤í…€ ëª¨ë¸ ì—†ìœ¼ë©´ ê¸°ë³¸ ëª¨ë¸
            models["yolo"] = YOLO("yolov8n.pt")
            logger.info("âœ… YOLOv8 ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    except Exception as e:
        logger.warning(f"âš ï¸ YOLOv8 ë¡œë“œ ì‹¤íŒ¨: {e}")
        models["yolo"] = None

    try:
        # CLIP ëª¨ë¸ ë¡œë”© (ë°°í¬í™˜ê²½ ì»¤ìŠ¤í…€ ëª¨ë¸ ì§€ì›)
        import clip
        import torch

        device = DEVICE

        # 1ìˆœìœ„: ë¡œì»¬ ì»¤ìŠ¤í…€ ëª¨ë¸
        local_clip_path = Path("train/models/clip_finetuned.pt")

        # 2ìˆœìœ„: ë°°í¬í™˜ê²½ ìºì‹œëœ ì»¤ìŠ¤í…€ ëª¨ë¸
        cached_clip_path = MODEL_CACHE_DIR / "clip_finetuned.pt"

        if local_clip_path.exists():
            # ë¡œì»¬ ì»¤ìŠ¤í…€ ëª¨ë¸ ì‚¬ìš©
            model, preprocess = clip.load(str(local_clip_path), device=device)
            logger.info("âœ… CLIP ë¡œì»¬ ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        elif cached_clip_path.exists():
            # ìºì‹œëœ ì»¤ìŠ¤í…€ ëª¨ë¸ ì‚¬ìš©
            model, preprocess = clip.load(str(cached_clip_path), device=device)
            logger.info("âœ… CLIP ìºì‹œëœ ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        elif IS_DEPLOYMENT:
            # ë°°í¬í™˜ê²½ì—ì„œ CLIP ì»¤ìŠ¤í…€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œë„
            custom_clip_url = os.getenv("CUSTOM_CLIP_URL")

            if custom_clip_url:
                logger.info(f"ğŸ“¥ CLIP ì»¤ìŠ¤í…€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: {custom_clip_url}")
                if download_model_from_url(custom_clip_url, cached_clip_path):
                    model, preprocess = clip.load(str(cached_clip_path), device=device)
                    logger.info("âœ… CLIP ë‹¤ìš´ë¡œë“œëœ ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                else:
                    logger.warning("âš ï¸ CLIP ì»¤ìŠ¤í…€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")
                    model, preprocess = clip.load("ViT-B/32", device=device)
                    logger.info("âœ… CLIP ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                model, preprocess = clip.load("ViT-B/32", device=device)
                logger.info("âœ… CLIP ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        else:
            # ë¡œì»¬í™˜ê²½ì—ì„œ ì»¤ìŠ¤í…€ ëª¨ë¸ ì—†ìœ¼ë©´ ê¸°ë³¸ ëª¨ë¸
            model, preprocess = clip.load("ViT-B/32", device=device)
            logger.info("âœ… CLIP ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        models["clip"] = {"model": model, "preprocess": preprocess}

    except Exception as e:
        logger.warning(f"âš ï¸ CLIP ë¡œë“œ ì‹¤íŒ¨: {e}")
        models["clip"] = None

    try:
        # OpenAI API ì„¤ì •
        from openai import OpenAI

        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            models["openai"] = OpenAI(api_key=api_key)
            logger.info("âœ… OpenAI API ì—°ê²° ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ OpenAI API í‚¤ ì—†ìŒ")
            models["openai"] = None

    except Exception as e:
        logger.warning(f"âš ï¸ OpenAI API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        models["openai"] = None

    logger.info(f"ğŸ¯ ê³ ì •í™•ë„ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ - í™˜ê²½: {ENVIRONMENT}")
    return models


def initialize_modules():
    """ëª¨ë“ˆ ì´ˆê¸°í™” ë° ë¡œë“œ"""
    global MODULES_LOADED, DAMAGE_CATEGORIES, CACHE_DIR

    try:
        # í™˜ê²½ë³„ ìµœì í™”ëœ ëª¨ë¸ ë¡œë“œ
        models = initialize_optimized_models()

        # ê¸°ë³¸ ì„¤ì • ê°’ë“¤
        DAMAGE_CATEGORIES = {
            "damage_types": [
                "ê· ì—´ (Cracks)",
                "ìˆ˜í•´ (Water damage)",
                "í™”ì¬ ì†ìƒ (Fire damage)",
                "ì§€ë¶• ì†ìƒ (Roof damage)",
                "ì°½ë¬¸/ë¬¸ ì†ìƒ (Window/Door damage)",
                "ê¸°ì´ˆ ì¹¨í•˜ (Foundation settlement)",
                "êµ¬ì¡°ì  ë³€í˜• (Structural deformation)",
                "ì™¸ë²½ ì†ìƒ (Facade damage)",
                "ì „ê¸°/ê¸°ê³„ ì‹œì„¤ ì†ìƒ (Electrical/Mechanical damage)",
            ]
        }
        CACHE_DIR = Path("./cache")

        MODULES_LOADED = True
        logger.info("âœ… ëª¨ë“  ëª¨ë“ˆì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤")

        # ë”ë¯¸ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ í˜¸í™˜ì„±ìš©)
        @st.cache_resource
        def create_faiss_vector_store():
            logger.info("FAISS ì œê±°ë¨ - Pandas ì§ì ‘ ì‚¬ìš©")
            return None

        def analyze_building_damage(*args, **kwargs):
            return {"message": "ìƒˆë¡œìš´ ë¶„ì„ ì—”ì§„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."}

        return {
            "analyze_building_damage": analyze_building_damage,
            "create_faiss_vector_store": create_faiss_vector_store,
            "models": models,
        }

    except Exception as e:
        st.error(f"ëª¨ë“ˆ ë¡œë”© ì˜¤ë¥˜: {e}")
        st.error("í•„ìš”í•œ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°œë°œìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")

        MODULES_LOADED = False
        DAMAGE_CATEGORIES = {}
        CACHE_DIR = Path("./cache")

        logger.error(f"ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {e}")

        # Fallback functions
        @st.cache_resource
        def create_faiss_vector_store():
            return None

        def analyze_building_damage(*args, **kwargs):
            return {"error": "ë¶„ì„ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        return {
            "analyze_building_damage": analyze_building_damage,
            "create_faiss_vector_store": create_faiss_vector_store,
            "models": {},
        }


def setup_directories():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
    upload_dir = CACHE_DIR / "uploads"
    results_dir = CACHE_DIR / "results"

    # ëª¨ë¸ ìºì‹œ ë””ë ‰í† ë¦¬ë„ ìƒì„±
    MODEL_CACHE_DIR.mkdir(parents=True, exist_ok=True)

    for directory in [upload_dir, results_dir]:
        directory.mkdir(parents=True, exist_ok=True)

    return upload_dir, results_dir


def get_app_config():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ë°˜í™˜"""
    return {
        "environment": ENVIRONMENT,
        "is_deployment": IS_DEPLOYMENT,
        "device": DEVICE,
        "batch_size": BATCH_SIZE,
        "max_image_size": MAX_IMAGE_SIZE,
        "modules_loaded": MODULES_LOADED,
        "vector_store_available": False,  # FAISS ì œê±°
        "damage_categories": DAMAGE_CATEGORIES,
        "cache_dir": CACHE_DIR,
        "model_cache_dir": MODEL_CACHE_DIR,
    }


def optimize_for_environment():
    """í™˜ê²½ë³„ ìµœì í™” ì„¤ì • ì ìš©"""
    # ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ì„±ëŠ¥ ì„¤ì • (ë°°í¬ í™˜ê²½ ìµœì í™” ì œê±°)
    if True:  # í•­ìƒ ì‹¤í–‰ (ê¸°ì¡´ IS_DEPLOYMENT ì¡°ê±´ ì œê±°)
        # ê¸°ë³¸ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ê³¼ë„í•œ ìµœì í™” ì œê±°)
        os.environ["TOKENIZERS_PARALLELISM"] = "true"  # ë³‘ë ¬ ì²˜ë¦¬ í™œì„±í™”
        os.environ["TRANSFORMERS_VERBOSITY"] = "info"
        # ë©”ëª¨ë¦¬ ì œí•œ ì œê±°
        # os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:256"  # ì œê±°
        # os.environ["OMP_NUM_THREADS"] = "2"  # ì œê±°
        # os.environ["MKL_NUM_THREADS"] = "2"  # ì œê±°

        # CPU ìŠ¤ë ˆë“œ ì œí•œ í•´ì œ
        import torch

        if hasattr(torch, "set_num_threads"):
            torch.set_num_threads(8)  # ë” ë§ì€ ìŠ¤ë ˆë“œ ì‚¬ìš©

    logger.info(f"ğŸ¯ í™˜ê²½ë³„ ìµœì í™” ì™„ë£Œ: {ENVIRONMENT}")
